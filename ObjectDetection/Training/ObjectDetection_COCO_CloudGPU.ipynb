{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ObjectDetection_COCO_CloudGPU.ipynb","version":"0.3.2","provenance":[{"file_id":"1c6p1t-d6GaBMvkE_wUVnl_MJLbiJXPBy","timestamp":1558471806345},{"file_id":"1cwe49p-MdzTUCIw2bNFWZzCd13bGhpHm","timestamp":1548356900878},{"file_id":"1QEhG_598QVfIHzrHkBlW5Vr-FDC_Sap3","timestamp":1547824581824},{"file_id":"1R5DRV991c3xzXP1UTi2UenaTe7_Mc4zz","timestamp":1547032224712}],"collapsed_sections":["BmalH_ZVaLXt","rgZK0zGcaeNK","8wh49MKrIq5f","CUhtxLQyUfj6"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"F_GEUYwohHoq","colab_type":"text"},"source":["# Mount Google Drive to access files"]},{"cell_type":"markdown","metadata":{"id":"W16u76U3kZuo","colab_type":"text"},"source":["---\n","# Imports & Config  "]},{"cell_type":"markdown","metadata":{"id":"cSVKRj-Y_FML","colab_type":"text"},"source":["## Config"]},{"cell_type":"code","metadata":{"id":"MN0GUp9P_Iwi","colab_type":"code","colab":{}},"source":["import os\n","\n","base_dir = \"/content/gdrive/My Drive/Masterarbeit\"\n","object_detection_dir = os.path.join(base_dir, \"ObjectDetection\")\n","image_classification = os.path.join(base_dir, \"ImageClassification\")\n","\n","classes_dict_file = object_detection_dir + \"/classes.pkl\"\n","objects_dict_file = object_detection_dir + \"/objects.pkl\"\n","images_dict_file = object_detection_dir + \"/images.pkl\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NihqGcD55V7","colab_type":"text"},"source":["## Mount GDrive"]},{"cell_type":"code","metadata":{"id":"MJHLlGTNgyM3","colab_type":"code","outputId":"f3f6f32f-7e47-4e35-9645-8109ae188968","executionInfo":{"status":"ok","timestamp":1558510006140,"user_tz":-120,"elapsed":2379,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FQ5DZ8qRsqUa","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"OC-m8H6ZV2zE","colab_type":"code","outputId":"f219360d-9233-4aec-b478-84bc1d59d0ab","executionInfo":{"status":"ok","timestamp":1558465603529,"user_tz":-120,"elapsed":29645,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["!git clone https://github.com/tensorflow/models.git /content/tf\n","!cd /content/tf/research; protoc object_detection/protos/*.proto --python_out=.\n","!cd /content/tf/research; export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim; python /content/tf/research/object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into '/content/tf'...\n","remote: Enumerating objects: 26, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 25955 (delta 10), reused 10 (delta 2), pack-reused 25929\u001b[K\n","Receiving objects: 100% (25955/25955), 508.55 MiB | 37.15 MiB/s, done.\n","Resolving deltas: 100% (15583/15583), done.\n","Checking out files: 100% (2912/2912), done.\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","............s...\n","----------------------------------------------------------------------\n","Ran 16 tests in 0.072s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Swj_IDpZgkf","colab_type":"code","outputId":"d99902e0-88d3-44c1-cfa2-e6c05459277d","executionInfo":{"status":"ok","timestamp":1558615637032,"user_tz":-120,"elapsed":3475,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["import os\n","import sys\n","\n","# For running inference on the TF-Hub module.\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","#...\n","sys.path.append('tf/research')\n","sys.path.append('tf/research/slim')\n","from object_detection.utils import dataset_util, config_util\n","from object_detection import model_main"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0523 12:47:13.581756 140575729608576 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"],"name":"stderr"},{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RUuoPkfmsUiH","colab_type":"code","colab":{}},"source":["class FLAGS_OD:\n","  image_dir = os.path.join(object_detection_dir, \"Images\")\n","  \n","  #tf records directory\n","  tf_records_dir = os.path.join(object_detection_dir, \"TFRecords\")\n","  #label_map directory\n","  label_map_dir = os.path.join(object_detection_dir, \"LabelMaps\")\n","  \n","  #class level to be considered\n","  class_level = [0,1]\n","  #how often the class of an object needs to occure to be considered\n","  min_class_occurence = 20\n","  \n","  #dataset split\n","  testing_percentage = 0\n","  validation_percentage = 10\n","  \n","  #pipeline config\n","  pipeline_config_dir = os.path.join(object_detection_dir, \"ConfigFiles\")\n","  \n","  #model checkpoints\n","  model_checkpoint_dir = os.path.join(object_detection_dir, \"ModelCheckpoints\")\n","  model_dir = os.path.join(object_detection_dir,\"Models\")\n","  \n","  #cloud configs\n","  cloud_config_dir = os.path.join(object_detection_dir, \"CloudConfigFiles\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v6Ti5t8xGEV9","colab_type":"text"},"source":["# Create DataSet"]},{"cell_type":"code","metadata":{"id":"8Psv1CuQIZQ0","colab_type":"code","outputId":"3e1d386d-2103-44a2-f8aa-36fc44c8dcac","executionInfo":{"status":"ok","timestamp":1558466298635,"user_tz":-120,"elapsed":519672,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":971}},"source":["!mkdir COCO\n","\n","!wget http://images.cocodataset.org/zips/train2014.zip\n","!wget http://images.cocodataset.org/zips/val2014.zip\n","!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n","!wget http://images.cocodataset.org/zips/test2014.zip\n","!wget http://images.cocodataset.org/annotations/image_info_test2014.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-05-21 19:09:42--  http://images.cocodataset.org/zips/train2014.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.97.227\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.97.227|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13510573713 (13G) [application/zip]\n","Saving to: ‘train2014.zip’\n","\n","train2014.zip       100%[===================>]  12.58G  50.7MB/s    in 4m 1s   \n","\n","2019-05-21 19:13:43 (53.4 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n","\n","--2019-05-21 19:13:44--  http://images.cocodataset.org/zips/val2014.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.233.27\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.233.27|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6645013297 (6.2G) [application/zip]\n","Saving to: ‘val2014.zip’\n","\n","val2014.zip         100%[===================>]   6.19G  53.3MB/s    in 2m 8s   \n","\n","2019-05-21 19:15:52 (49.6 MB/s) - ‘val2014.zip’ saved [6645013297/6645013297]\n","\n","--2019-05-21 19:15:53--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.108.139\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.108.139|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 252872794 (241M) [application/zip]\n","Saving to: ‘annotations_trainval2014.zip’\n","\n","annotations_trainva 100%[===================>] 241.16M  68.4MB/s    in 3.5s    \n","\n","2019-05-21 19:15:56 (68.4 MB/s) - ‘annotations_trainval2014.zip’ saved [252872794/252872794]\n","\n","--2019-05-21 19:15:57--  http://images.cocodataset.org/zips/test2014.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.237.203\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.237.203|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6660437059 (6.2G) [application/zip]\n","Saving to: ‘test2014.zip’\n","\n","test2014.zip        100%[===================>]   6.20G  39.9MB/s    in 2m 19s  \n","\n","2019-05-21 19:18:16 (45.7 MB/s) - ‘test2014.zip’ saved [6660437059/6660437059]\n","\n","--2019-05-21 19:18:17--  http://images.cocodataset.org/annotations/image_info_test2014.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.130.67\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.130.67|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 763464 (746K) [application/zip]\n","Saving to: ‘image_info_test2014.zip’\n","\n","image_info_test2014 100%[===================>] 745.57K  --.-KB/s    in 0.07s   \n","\n","2019-05-21 19:18:17 (10.8 MB/s) - ‘image_info_test2014.zip’ saved [763464/763464]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7D9Y8iIKywME","colab_type":"code","colab":{}},"source":["!unzip -q train2014.zip -d COCO\n","!unzip -q val2014.zip -d COCO\n","!unzip -q annotations_trainval2014.zip -d COCO\n","!unzip -q test2014.zip -d COCO\n","!unzip -q image_info_test2014.zip -d COCO"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3cY13DVy7Bt","colab_type":"code","colab":{}},"source":["!rm train2014.zip\n","!rm val2014.zip\n","!rm annotations_trainval2014.zip\n","!rm test2014.zip\n","!rm image_info_test2014.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hOIJVD43Z8k","colab_type":"code","outputId":"e67641fe-472e-49a1-f040-3fab55315460","executionInfo":{"status":"ok","timestamp":1558466926710,"user_tz":-120,"elapsed":6049,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["!du -sh COCO/test2014\n","!du -sh COCO/train2014\n","!du -sh COCO/val2014"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6.3G\tCOCO/test2014\n","13G\tCOCO/train2014\n","6.3G\tCOCO/val2014\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3mCCRYWp4h1v","colab_type":"code","outputId":"f5c48650-0a2f-4c9e-b1d5-4b51a2b80651","executionInfo":{"status":"ok","timestamp":1558468492444,"user_tz":-120,"elapsed":1476,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["import json\n","import pprint\n","\n","def present_keys_recursive(var):\n","  if isinstance(var, dict):\n","    d = dict()\n","    for k,v in var.items():\n","      d[k] = present_keys_recursive(v)\n","  elif isinstance(var, list):\n","    d = [present_keys_recursive(var[0])]\n","  else:\n","    d = type(var)\n","  return d\n","\n","with open(\"COCO/annotations/image_info_test2014.json\", \"r\") as file:\n","  j = json.load(file)\n","\n","layout = present_keys_recursive(j)\n","\n","pp = pprint.PrettyPrinter(indent=2)\n","\n","pp.pprint(layout)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{ 'categories': [ { 'id': <class 'int'>,\n","                    'name': <class 'str'>,\n","                    'supercategory': <class 'str'>}],\n","  'images': [ { 'coco_url': <class 'str'>,\n","                'date_captured': <class 'str'>,\n","                'file_name': <class 'str'>,\n","                'height': <class 'int'>,\n","                'id': <class 'int'>,\n","                'license': <class 'int'>,\n","                'width': <class 'int'>}],\n","  'info': { 'contributor': <class 'str'>,\n","            'date_created': <class 'str'>,\n","            'description': <class 'str'>,\n","            'url': <class 'str'>,\n","            'version': <class 'str'>,\n","            'year': <class 'int'>},\n","  'licenses': [ { 'id': <class 'int'>,\n","                  'name': <class 'str'>,\n","                  'url': <class 'str'>}]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SpppiDYdnphM","colab_type":"code","outputId":"7d45579a-5c5d-41fc-92e0-e6a41028edb3","executionInfo":{"status":"ok","timestamp":1558468756830,"user_tz":-120,"elapsed":3885,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["!cd /content/tf/research; python object_detection/dataset_tools/create_coco_tf_record.py --logtostderr --train_image_dir=\"/content/COCO/train2014\" --val_image_dir=\"/content/COCO/val2014\" --train_annotations_file=\"/content/COCO/annotations/image_info_test2014.json.json\" --val_annotations_file=\"/content/COCO/annotations/instances_val2014.json\" --output_dir=\"/content/COCO\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"object_detection/dataset_tools/create_coco_tf_record.py\", line 45, in <module>\n","    from object_detection.dataset_tools import tf_record_creation_util\n","ModuleNotFoundError: No module named 'object_detection'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2UQSw3d1_k6V","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import hashlib\n","import io\n","import json\n","import os\n","import contextlib2\n","import numpy as np\n","import PIL.Image\n","\n","from pycocotools import mask\n","import tensorflow as tf\n","\n","from object_detection.dataset_tools import tf_record_creation_util\n","from object_detection.utils import dataset_util\n","from object_detection.utils import label_map_util"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OqxjUdm_l0z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":401},"outputId":"a5a44360-46a4-43e1-831f-768debe68264","executionInfo":{"status":"error","timestamp":1558615954450,"user_tz":-120,"elapsed":1265,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}}},"source":["tf.flags.DEFINE_boolean('include_masks', False,\n","                        'Whether to include instance segmentations masks '\n","                        '(PNG encoded) in the result. default: False.')\n","tf.flags.DEFINE_string('train_image_dir', '',\n","                       'Training image directory.')\n","tf.flags.DEFINE_string('val_image_dir', '',\n","                       'Validation image directory.')\n","tf.flags.DEFINE_string('train_annotations_file', '',\n","                       'Training annotations JSON file.')\n","tf.flags.DEFINE_string('val_annotations_file', '',\n","                       'Validation annotations JSON file.')\n","tf.flags.DEFINE_string('output_dir', '/content/COCO/', 'Output data directory.')"],"execution_count":18,"outputs":[{"output_type":"error","ename":"DuplicateFlagError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-c978a13e3bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.flags.DEFINE_boolean('include_masks', False,\n\u001b[0;32m----> 2\u001b[0;31m                         \u001b[0;34m'Whether to include instance segmentations masks '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                         '(PNG encoded) in the result. default: False.')\n\u001b[1;32m      4\u001b[0m tf.flags.DEFINE_string('train_image_dir', '',\n\u001b[1;32m      5\u001b[0m                        'Training image directory.')\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_boolean\u001b[0;34m(name, default, help, flag_values, module_name, **args)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   DEFINE_flag(_flag.BooleanFlag(name, default, help, **args),\n\u001b[0;32m--> 268\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'include_masks' is defined twice. First from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py, Second from /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py.  Description from first occurrence: Whether to include instance segmentations masks (PNG encoded) in the result. default: False."]}]},{"cell_type":"code","metadata":{"id":"2ivTw8yd_N-K","colab_type":"code","colab":{}},"source":["def create_tf_example(image,\n","                      annotations_list,\n","                      image_dir,\n","                      category_index,\n","                      include_masks=False):\n","  \"\"\"Converts image and annotations to a tf.Example proto.\n","  Args:\n","    image: dict with keys:\n","      [u'license', u'file_name', u'coco_url', u'height', u'width',\n","      u'date_captured', u'flickr_url', u'id']\n","    annotations_list:\n","      list of dicts with keys:\n","      [u'segmentation', u'area', u'iscrowd', u'image_id',\n","      u'bbox', u'category_id', u'id']\n","      Notice that bounding box coordinates in the official COCO dataset are\n","      given as [x, y, width, height] tuples using absolute coordinates where\n","      x, y represent the top-left (0-indexed) corner.  This function converts\n","      to the format expected by the Tensorflow Object Detection API (which is\n","      which is [ymin, xmin, ymax, xmax] with coordinates normalized relative\n","      to image size).\n","    image_dir: directory containing the image files.\n","    category_index: a dict containing COCO category information keyed\n","      by the 'id' field of each category.  See the\n","      label_map_util.create_category_index function.\n","    include_masks: Whether to include instance segmentations masks\n","      (PNG encoded) in the result. default: False.\n","  Returns:\n","    example: The converted tf.Example\n","    num_annotations_skipped: Number of (invalid) annotations that were ignored.\n","  Raises:\n","    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n","  \"\"\"\n","  FLAGS = tf.app.flags.FLAGS\n","  image_height = image['height']\n","  image_width = image['width']\n","  filename = image['file_name']\n","  image_id = image['id']\n","\n","  full_path = os.path.join(image_dir, filename)\n","  with tf.gfile.GFile(full_path, 'rb') as fid:\n","    encoded_jpg = fid.read()\n","  encoded_jpg_io = io.BytesIO(encoded_jpg)\n","  image = PIL.Image.open(encoded_jpg_io)\n","  key = hashlib.sha256(encoded_jpg).hexdigest()\n","\n","  xmin = []\n","  xmax = []\n","  ymin = []\n","  ymax = []\n","  is_crowd = []\n","  category_names = []\n","  category_ids = []\n","  area = []\n","  encoded_mask_png = []\n","  num_annotations_skipped = 0\n","  for object_annotations in annotations_list:\n","    (x, y, width, height) = tuple(object_annotations['bbox'])\n","    if width <= 0 or height <= 0:\n","      num_annotations_skipped += 1\n","      continue\n","    if x + width > image_width or y + height > image_height:\n","      num_annotations_skipped += 1\n","      continue\n","    xmin.append(float(x) / image_width)\n","    xmax.append(float(x + width) / image_width)\n","    ymin.append(float(y) / image_height)\n","    ymax.append(float(y + height) / image_height)\n","    is_crowd.append(object_annotations['iscrowd'])\n","    category_id = int(object_annotations['category_id'])\n","    category_ids.append(category_id)\n","    category_names.append(category_index[category_id]['name'].encode('utf8'))\n","    area.append(object_annotations['area'])\n","\n","    if include_masks:\n","      run_len_encoding = mask.frPyObjects(object_annotations['segmentation'],\n","                                          image_height, image_width)\n","      binary_mask = mask.decode(run_len_encoding)\n","      if not object_annotations['iscrowd']:\n","        binary_mask = np.amax(binary_mask, axis=2)\n","      pil_image = PIL.Image.fromarray(binary_mask)\n","      output_io = io.BytesIO()\n","      pil_image.save(output_io, format='PNG')\n","      encoded_mask_png.append(output_io.getvalue())\n","  feature_dict = {\n","      'image/height':\n","          dataset_util.int64_feature(image_height),\n","      'image/width':\n","          dataset_util.int64_feature(image_width),\n","      'image/filename':\n","          dataset_util.bytes_feature(filename.encode('utf8')),\n","      'image/source_id':\n","          dataset_util.bytes_feature(str(image_id).encode('utf8')),\n","      'image/key/sha256':\n","          dataset_util.bytes_feature(key.encode('utf8')),\n","      'image/encoded':\n","          dataset_util.bytes_feature(encoded_jpg),\n","      'image/format':\n","          dataset_util.bytes_feature('jpeg'.encode('utf8')),\n","      'image/object/bbox/xmin':\n","          dataset_util.float_list_feature(xmin),\n","      'image/object/bbox/xmax':\n","          dataset_util.float_list_feature(xmax),\n","      'image/object/bbox/ymin':\n","          dataset_util.float_list_feature(ymin),\n","      'image/object/bbox/ymax':\n","          dataset_util.float_list_feature(ymax),\n","      'image/object/class/text':\n","          dataset_util.bytes_list_feature(category_names),\n","      'image/object/is_crowd':\n","          dataset_util.int64_list_feature(is_crowd),\n","      'image/object/area':\n","          dataset_util.float_list_feature(area),\n","  }\n","  if include_masks:\n","    feature_dict['image/object/mask'] = (\n","        dataset_util.bytes_list_feature(encoded_mask_png))\n","  example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n","  return key, example, num_annotations_skipped"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kBdk9HoH_dYO","colab_type":"code","colab":{}},"source":["def _create_tf_record_from_coco_annotations(\n","    annotations_file, image_dir, output_path, include_masks, num_shards):\n","  \"\"\"Loads COCO annotation json files and converts to tf.Record format.\n","  Args:\n","    annotations_file: JSON file containing bounding box annotations.\n","    image_dir: Directory containing the image files.\n","    output_path: Path to output tf.Record file.\n","    include_masks: Whether to include instance segmentations masks\n","      (PNG encoded) in the result. default: False.\n","    num_shards: number of output file shards.\n","  \"\"\"\n","  FLAGS = tf.app.flags.FLAGS\n","  with contextlib2.ExitStack() as tf_record_close_stack, \\\n","      tf.gfile.GFile(annotations_file, 'r') as fid:\n","    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n","        tf_record_close_stack, output_path, num_shards)\n","    groundtruth_data = json.load(fid)\n","    images = groundtruth_data['images']\n","    category_index = label_map_util.create_category_index(\n","        groundtruth_data['categories'])\n","\n","    annotations_index = {}\n","    if 'annotations' in groundtruth_data:\n","      tf.logging.info(\n","          'Found groundtruth annotations. Building annotations index.')\n","      for annotation in groundtruth_data['annotations']:\n","        image_id = annotation['image_id']\n","        if image_id not in annotations_index:\n","          annotations_index[image_id] = []\n","        annotations_index[image_id].append(annotation)\n","    missing_annotation_count = 0\n","    for image in images:\n","      image_id = image['id']\n","      if image_id not in annotations_index:\n","        missing_annotation_count += 1\n","        annotations_index[image_id] = []\n","    tf.logging.info('%d images are missing annotations.',\n","                    missing_annotation_count)\n","\n","    total_num_annotations_skipped = 0\n","    for idx, image in enumerate(images):\n","      if idx % 100 == 0:\n","        tf.logging.info('On image %d of %d', idx, len(images))\n","      annotations_list = annotations_index[image['id']]\n","      _, tf_example, num_annotations_skipped = create_tf_example(\n","          image, annotations_list, image_dir, category_index, include_masks)\n","      total_num_annotations_skipped += num_annotations_skipped\n","      shard_idx = idx % num_shards\n","      output_tfrecords[shard_idx].write(tf_example.SerializeToString())\n","    tf.logging.info('Finished writing, skipped %d annotations.',\n","                    total_num_annotations_skipped)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwxMTfZe_UwP","colab_type":"code","colab":{}},"source":["FLAGS = tf.app.flags.FLAGS\n","\n","def main(_):\n","  \n","  if not tf.gfile.IsDirectory(FLAGS.output_dir):\n","    tf.gfile.MakeDirs(FLAGS.output_dir)\n","  train_output_path = os.path.join(FLAGS.output_dir, 'coco_train.record')\n","  val_output_path = os.path.join(FLAGS.output_dir, 'coco_val.record')\n","  testdev_output_path = os.path.join(FLAGS.output_dir, 'coco_testdev.record')\n","\n","  if FLAGS.train_image_dir and FLAGS.train_annotations_file:\n","    _create_tf_record_from_coco_annotations(\n","        FLAGS.train_annotations_file,\n","        FLAGS.train_image_dir,\n","        train_output_path,\n","        FLAGS.include_masks,\n","        num_shards=100)\n","  if FLAGS.val_image_dir and FLAGS.val_annotations_file:\n","    _create_tf_record_from_coco_annotations(\n","        FLAGS.val_annotations_file,\n","        FLAGS.val_image_dir,\n","        val_output_path,\n","        FLAGS.include_masks,\n","        num_shards=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgTQ4ZRB_QFM","colab_type":"code","outputId":"83f6e31e-683b-4f7d-eeb0-f23576271d15","executionInfo":{"status":"error","timestamp":1558615994142,"user_tz":-120,"elapsed":17724,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":2006}},"source":["FLAGS.train_image_dir = ''\n","FLAGS.train_annotations_file = ''\n","FLAGS.val_image_dir = \"COCO/val2014\"\n","FLAGS.val_annotations_file = \"instances_minival2014.json\"\n","\n","tf.app.run(main)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Found groundtruth annotations. Building annotations index.\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:46.843699 140575729608576 <ipython-input-15-8f22e8fede56>:24] Found groundtruth annotations. Building annotations index.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:48 images are missing annotations.\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:46.875041 140575729608576 <ipython-input-15-8f22e8fede56>:37] 48 images are missing annotations.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 0 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:46.877511 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 0 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 100 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:47.323271 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 100 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 200 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:47.763982 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 200 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 300 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:48.201561 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 300 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 400 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:48.632449 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 400 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 500 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:49.160656 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 500 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 600 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:49.590457 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 600 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 700 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:49.991130 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 700 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 800 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:50.445779 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 800 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 900 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:50.867886 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 900 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1000 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:52.043868 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1000 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1100 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:52.512719 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1100 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1200 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:52.933679 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1200 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1300 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:53.330274 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1300 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1400 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:53.771728 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1400 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1500 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:54.450190 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1500 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1600 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:54.862162 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1600 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1700 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:55.290199 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1700 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1800 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:55.767122 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1800 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 1900 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:56.840580 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 1900 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2000 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:57.260705 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2000 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2100 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:57.689668 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2100 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2200 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:58.072493 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2200 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2300 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:58.487453 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2300 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2400 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:58.979345 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2400 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2500 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:52:59.909812 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2500 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2600 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:00.300503 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2600 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2700 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:00.698617 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2700 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2800 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:01.132735 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2800 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 2900 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:01.548774 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 2900 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3000 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:02.064506 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3000 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3100 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:03.006754 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3100 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3200 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:03.422990 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3200 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3300 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:03.878088 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3300 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3400 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:04.336281 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3400 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3500 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:04.760146 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3500 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3600 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:05.234647 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3600 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3700 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:05.698673 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3700 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3800 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:06.910961 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3800 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 3900 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:07.327778 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 3900 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4000 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:07.780851 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4000 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4100 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:08.202405 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4100 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4200 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:08.723097 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4200 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4300 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:09.166550 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4300 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4400 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:10.155192 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4400 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4500 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:10.624648 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4500 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4600 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:11.062668 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4600 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4700 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:11.574354 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4700 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4800 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:12.009766 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4800 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:On image 4900 of 5000\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:12.487566 140575729608576 <ipython-input-15-8f22e8fede56>:42] On image 4900 of 5000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished writing, skipped 0 annotations.\n"],"name":"stdout"},{"output_type":"stream","text":["I0523 12:53:13.486211 140575729608576 <ipython-input-15-8f22e8fede56>:50] Finished writing, skipped 0 annotations.\n"],"name":"stderr"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"n3_broKoDmax","colab_type":"code","colab":{}},"source":["!rm -r COCO/test2014\n","!rm -r COCO/train2014 \n","!rm -r COCO/val2014\n","!rm -r COCO/annotations"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKIC9QppDy9p","colab_type":"code","colab":{}},"source":["!cp COCO/coco_train.record* /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/Datasets/COCO/train\n","!cp COCO/coco_val.record* /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/Datasets/COCO/val"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsiDJktvvgw1","colab_type":"text"},"source":["# GCloud Setup"]},{"cell_type":"markdown","metadata":{"id":"Jjc5oMFFToqH","colab_type":"text"},"source":["ProjectId: objectdetection-229309\n","\n","StorageAdress: gs://holoselecta_objectdetection/\n","\n","tpuServiceAccount: service-727747150776@cloud-tpu.iam.gserviceaccount.com\n","\n","\n","---\n","\n","\n","ProjectId: holoselecta\n","\n","StorageAdress: gs://holoselecta_objectdetection_2/\n","\n","tpuServiceAccount: service-474819640395@cloud-tpu.iam.gserviceaccount.com"]},{"cell_type":"markdown","metadata":{"id":"mqfOvoN2UdFj","colab_type":"text"},"source":["## Init"]},{"cell_type":"code","metadata":{"id":"ykUfETRDvk_s","colab_type":"code","outputId":"0241c982-0e60-46de-96ac-f06707d43567","executionInfo":{"status":"ok","timestamp":1558510083048,"user_tz":-120,"elapsed":52929,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":1060}},"source":["!gcloud init"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Welcome! This command will take you through the configuration of gcloud.\n","\n","Settings from your current configuration [default] are:\n","component_manager:\n","  disable_update_check: 'True'\n","\n","Pick configuration to use:\n"," [1] Re-initialize this configuration [default] with new settings \n"," [2] Create a new configuration\n","Please enter your numeric choice:  1\n","\n","Your current configuration has been set to: [default]\n","\n","You can skip diagnostics next time by using the following flag:\n","  gcloud init --skip-diagnostics\n","\n","Network diagnostic detects and fixes local network connection issues.\n","Reachability Check passed.\n","Network diagnostic passed (1/1 checks passed).\n","\n","You must log in to continue. Would you like to log in (Y/n)?  y\n","\n","Go to the following link in your browser:\n","\n","    https://accounts.google.com/o/oauth2/auth?redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&prompt=select_account&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&access_type=offline\n","\n","\n","Enter verification code: 4/UgEV7BF5RqGTOHiamQ3hO_682Cj8Wvom7C0izbD6FI2Z6uP8jdBsn_o\n","\n","\n","To take a quick anonymous survey, run:\n","  $ gcloud alpha survey\n","\n","You are logged in as: [grundtob@gmail.com].\n","\n","Pick cloud project to use: \n"," [1] objectdetection-229309\n"," [2] test-cloud-datalab-226917\n"," [3] Create a new project\n","Please enter numeric choice or text value (must exactly match list \n","item):  1\n","\n","Your current project has been set to: [objectdetection-229309].\n","\n","Do you want to configure a default Compute Region and Zone? (Y/n)?  n\n","\n","Your Google Cloud SDK is configured and ready to use!\n","\n","* Commands that require authentication will use grundtob@gmail.com by default\n","* Commands will reference project `objectdetection-229309` by default\n","Run `gcloud help config` to learn how to change individual settings\n","\n","This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n","Run `gcloud topic configurations` to learn more.\n","\n","Some things to try next:\n","\n","* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n","* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CUhtxLQyUfj6","colab_type":"text"},"source":["## Setup \n","(only done once)  "]},{"cell_type":"code","metadata":{"id":"DjVmlyWKzZB2","colab_type":"code","outputId":"d97f7291-aec2-4796-920a-1722d8d95aa5","executionInfo":{"status":"ok","timestamp":1551681816391,"user_tz":-60,"elapsed":3838,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!gsutil mb gs://holoselecta_objectdetection_3"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Creating gs://holoselecta_objectdetection_3/...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gnLuR4Dwz7c9","colab_type":"code","outputId":"ecbd0a66-1b7d-4adf-8c98-5baa7394011c","executionInfo":{"status":"ok","timestamp":1551639570197,"user_tz":-60,"elapsed":3014,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["!curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\" https://ml.googleapis.com/v1/projects/holoselecta:getConfig"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{\n","  \"serviceAccount\": \"service-454653118122@cloud-ml.google.com.iam.gserviceaccount.com\",\n","  \"serviceAccountProject\": \"474819640395\",\n","  \"config\": {\n","    \"tpuServiceAccount\": \"service-474819640395@cloud-tpu.iam.gserviceaccount.com\"\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J0LcdlE10ZFl","colab_type":"code","outputId":"780b3caa-e147-4dd2-a49e-c7d30bef4cd7","executionInfo":{"status":"ok","timestamp":1551639636328,"user_tz":-60,"elapsed":2459,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["!gcloud projects add-iam-policy-binding holoselecta  --member serviceAccount:service-474819640395@cloud-tpu.iam.gserviceaccount.com --role roles/ml.serviceAgent"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Updated IAM policy for project [holoselecta].\n","bindings:\n","- members:\n","  - serviceAccount:service-454653118122@cloud-ml.google.com.iam.gserviceaccount.com\n","  - serviceAccount:service-474819640395@cloud-tpu.iam.gserviceaccount.com\n","  role: roles/ml.serviceAgent\n","- members:\n","  - user:hyve.tobiasgrundmann@gmail.com\n","  role: roles/owner\n","etag: BwWDNUFQl_Q=\n","version: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1LVHST726PEg","colab_type":"text"},"source":["## Copy Data\n"]},{"cell_type":"code","metadata":{"id":"ALgoh3PQ_2KE","colab_type":"code","outputId":"11864a15-8caa-4d7f-c8d0-18f6c1993dec","executionInfo":{"status":"ok","timestamp":1558553437168,"user_tz":-120,"elapsed":18686,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":401}},"source":["!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","!tar -xvf faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","!rm faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-05-22 19:30:19--  http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.111.128, 2607:f8b0:4001:c07::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.111.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 672221478 (641M) [application/x-tar]\n","Saving to: ‘faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz’\n","\n","faster_rcnn_incepti 100%[===================>] 641.08M   170MB/s    in 3.8s    \n","\n","2019-05-22 19:30:23 (170 MB/s) - ‘faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz’ saved [672221478/672221478]\n","\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt.index\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/checkpoint\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/pipeline.config\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt.data-00000-of-00001\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt.meta\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model/\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model/saved_model.pb\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model/variables/\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/frozen_inference_graph.pb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p3uqRG-60zvI","colab_type":"code","outputId":"d99113d1-21de-40da-dde1-b07b271e6385","executionInfo":{"status":"ok","timestamp":1558513902494,"user_tz":-120,"elapsed":6736,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["#!gsutil -m cp gdrive/My\\ Drive/Masterarbeit/ObjectDetection/Datasets/COCO/train/* gs://holoselecta_objectdetection/resnet800/data/\n","#!gsutil -m cp gdrive/My\\ Drive/Masterarbeit/ObjectDetection/Datasets/COCO/val/* gs://holoselecta_objectdetection/resnet800/data/\n","#!gsutil -m cp ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/model.ckpt.* gs://holoselecta_objectdetection/resnet800/data/\n","!gsutil cp gdrive/My\\ Drive/Masterarbeit/ObjectDetection/ConfigFiles/ssd_mobilenet_v1_fpn_shared_box_predictor_800x800_coco14_sync_cloud.config gs://holoselecta_objectdetection/resnet800/data/pipeline.config\n","#!gsutil cp /content/tf/research/object_detection/data/mscoco_label_map.pbtxt gs://holoselecta_objectdetection/resnet800/train/label_map.pbtxt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Copying file://gdrive/My Drive/Masterarbeit/ObjectDetection/ConfigFiles/ssd_mobilenet_v1_fpn_shared_box_predictor_800x800_coco14_sync_cloud.config [Content-Type=application/octet-stream]...\n","- [1 files][  4.3 KiB/  4.3 KiB]                                                \n","Operation completed over 1 objects/4.3 KiB.                                      \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uXNEXNnhnLrb","colab_type":"code","colab":{}},"source":["!cd /content/tf/research; bash object_detection/dataset_tools/create_pycocotools_package.sh /tmp/pycocotools\n","!cd /content/tf/research; python setup.py sdist\n","!cd /content/tf/research; (cd slim && python setup.py sdist)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4FdrDh0VfQi","colab_type":"text"},"source":["# Run"]},{"cell_type":"code","metadata":{"id":"3NnEVG-OjG7g","colab_type":"code","outputId":"47197bbe-78c3-492c-b058-74134face1ad","executionInfo":{"status":"ok","timestamp":1558513916511,"user_tz":-120,"elapsed":10069,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":2028}},"source":["#check data is there should be 8 + 2 files\n","!gsutil ls gs://holoselecta_objectdetection/resnet800/data\n","!gsutil ls gs://holoselecta_objectdetection/resnet800/train"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00000-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00001-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00002-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00003-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00004-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00005-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00006-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00007-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00008-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00009-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00010-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00011-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00012-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00013-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00014-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00015-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00016-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00017-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00018-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00019-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00020-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00021-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00022-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00023-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00024-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00025-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00026-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00027-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00028-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00029-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00030-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00031-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00032-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00033-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00034-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00035-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00036-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00037-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00038-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00039-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00040-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00041-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00042-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00043-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00044-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00045-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00046-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00047-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00048-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00049-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00050-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00051-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00052-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00053-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00054-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00055-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00056-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00057-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00058-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00059-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00060-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00061-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00062-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00063-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00064-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00065-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00066-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00067-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00068-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00069-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00070-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00071-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00072-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00073-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00074-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00075-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00076-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00077-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00078-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00079-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00080-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00081-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00082-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00083-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00084-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00085-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00086-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00087-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00088-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00089-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00090-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00091-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00092-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00093-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00094-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00095-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00096-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00097-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00098-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_train.record-00099-of-00100\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00000-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00001-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00002-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00003-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00004-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00005-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00006-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00007-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00008-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/coco_val.record-00009-of-00010\n","gs://holoselecta_objectdetection/resnet800/data/model.ckpt.data-00000-of-00001\n","gs://holoselecta_objectdetection/resnet800/data/model.ckpt.index\n","gs://holoselecta_objectdetection/resnet800/data/model.ckpt.meta\n","gs://holoselecta_objectdetection/resnet800/data/pipeline.config\n","gs://holoselecta_objectdetection/resnet800/train/label_map.pbtxt\n","gs://holoselecta_objectdetection/resnet800/train/packages/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jGM_A0OgVdQy","colab_type":"code","outputId":"698cb417-fde3-4ae6-c1e9-bb20339783e0","executionInfo":{"status":"ok","timestamp":1558513945747,"user_tz":-120,"elapsed":23823,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":228}},"source":["!cd /content/tf/research; gcloud ml-engine jobs submit training object_detection_`date +%m_%d_%Y_%H_%M_%S` --python-version 3.5 --runtime-version 1.12 --job-dir=gs://holoselecta_objectdetection/resnet800/train --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz --module-name object_detection.model_main --region us-central1 --config /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/CloudConfigFiles/standard_p100_no_worker.yml -- --model_dir=gs://holoselecta_objectdetection/resnet800/train --pipeline_config_path=gs://holoselecta_objectdetection/resnet800/data/pipeline.config"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[1;33mWARNING:\u001b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n","Job [object_detection_05_22_2019_08_32_04] submitted successfully.\n","Your job is still active. You may view the status of your job with the command\n","\n","  $ gcloud ai-platform jobs describe object_detection_05_22_2019_08_32_04\n","\n","or continue streaming the logs with the command\n","\n","  $ gcloud ai-platform jobs stream-logs object_detection_05_22_2019_08_32_04\n","jobId: object_detection_05_22_2019_08_32_04\n","state: QUEUED\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BmssgCdpYqKl","colab_type":"code","outputId":"dbef5371-6524-4461-ea39-073821b4f9d2","executionInfo":{"status":"ok","timestamp":1558251602134,"user_tz":-120,"elapsed":3245,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":1043}},"source":["!gcloud ai-platform jobs describe object_detection_05_19_2019_07_24_21"],"execution_count":0,"outputs":[{"output_type":"stream","text":["createTime: '2019-05-19T07:24:30Z'\n","endTime: '2019-05-19T07:35:56Z'\n","errorMessage: |-\n","  The replica master 0 exited with a non-zero status of 1. \n","  Traceback (most recent call last):\n","    [...]\n","    File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1075, in _get_features_and_labels_from_input_fn\n","      self._call_input_fn(input_fn, mode))\n","    File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1162, in _call_input_fn\n","      return input_fn(**kwargs)\n","    File \"/root/.local/lib/python3.5/site-packages/object_detection/inputs.py\", line 525, in _train_input_fn\n","      batch_size=params['batch_size'] if params else train_config.batch_size)\n","    File \"/root/.local/lib/python3.5/site-packages/object_detection/builders/dataset_builder.py\", line 124, in build\n","      num_additional_channels=input_reader_config.num_additional_channels)\n","    File \"/root/.local/lib/python3.5/site-packages/object_detection/data_decoders/tf_example_decoder.py\", line 307, in __init__\n","      default_value=''),\n","    File \"/root/.local/lib/python3.5/site-packages/object_detection/data_decoders/tf_example_decoder.py\", line 59, in __init__\n","      label_map_proto_file, use_display_name=False)\n","    File \"/root/.local/lib/python3.5/site-packages/object_detection/utils/label_map_util.py\", line 164, in get_label_map_dict\n","      label_map = load_labelmap(label_map_path)\n","    File \"/root/.local/lib/python3.5/site-packages/object_detection/utils/label_map_util.py\", line 133, in load_labelmap\n","      label_map_string = fid.read()\n","    File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py\", line 125, in read\n","      self._preread_check()\n","    File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py\", line 85, in _preread_check\n","      compat.as_bytes(self.__name), 1024 * 512, status)\n","    File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n","      c_api.TF_GetCode(self.status.status))\n","  tensorflow.python.framework.errors_impl.NotFoundError: data/label_map.pbtxt; No such file or directory\n","\n","  To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=142071610554&resource=ml_job%2Fjob_id%2Fobject_detection_05_19_2019_07_24_21&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%22object_detection_05_19_2019_07_24_21%22\n","etag: zrAtn0VWh8w=\n","jobId: object_detection_05_19_2019_07_24_21\n","startTime: '2019-05-19T07:26:20Z'\n","state: FAILED\n","trainingInput:\n","  args:\n","  - --model_dir=gs://holoselecta_objectdetection/resnet50/train\n","  - --pipeline_config_path=gs://holoselecta_objectdetection/resnet50/data/pipeline.config\n","  jobDir: gs://holoselecta_objectdetection/resnet50/train\n","  masterType: standard_p100\n","  packageUris:\n","  - gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/object_detection-0.1.tar.gz\n","  - gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/slim-0.1.tar.gz\n","  - gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/pycocotools-2.0.tar.gz\n","  pythonModule: object_detection.model_main\n","  pythonVersion: '3.5'\n","  region: us-central1\n","  runtimeVersion: '1.12'\n","  scaleTier: CUSTOM\n","trainingOutput:\n","  consumedMLUnits: 0.62\n","\n","View job in the Cloud Console at:\n","https://console.cloud.google.com/ml/jobs/object_detection_05_19_2019_07_24_21?project=objectdetection-229309\n","\n","View logs at:\n","https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fobject_detection_05_19_2019_07_24_21&project=objectdetection-229309\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PHpWmx5pri-h","colab_type":"code","outputId":"c572dff8-e725-471d-e3a8-07fd3b9377dc","executionInfo":{"status":"ok","timestamp":1558279416565,"user_tz":-120,"elapsed":3613,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":592}},"source":["!gsutil ls gs://holoselecta_objectdetection/resnet50/train/*"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gs://holoselecta_objectdetection/resnet50/train/\n","gs://holoselecta_objectdetection/resnet50/train/checkpoint\n","gs://holoselecta_objectdetection/resnet50/train/events.out.tfevents.1558252346.cmle-training-11657413241799530257\n","gs://holoselecta_objectdetection/resnet50/train/graph.pbtxt\n","gs://holoselecta_objectdetection/resnet50/train/label_map.pbtxt\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-1766.data-00000-of-00001\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-1766.index\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-1766.meta\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-3468.data-00000-of-00001\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-3468.index\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-3468.meta\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-5187.data-00000-of-00001\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-5187.index\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-5187.meta\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-6996.data-00000-of-00001\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-6996.index\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-6996.meta\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-7000.data-00000-of-00001\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-7000.index\n","gs://holoselecta_objectdetection/resnet50/train/model.ckpt-7000.meta\n","gs://holoselecta_objectdetection/resnet50/train/timestamp\n","\n","gs://holoselecta_objectdetection/resnet50/train/eval_0/:\n","gs://holoselecta_objectdetection/resnet50/train/eval_0/\n","gs://holoselecta_objectdetection/resnet50/train/eval_0/events.out.tfevents.1558253017.cmle-training-11657413241799530257\n","\n","gs://holoselecta_objectdetection/resnet50/train/export/:\n","gs://holoselecta_objectdetection/resnet50/train/export/\n","gs://holoselecta_objectdetection/resnet50/train/export/Servo/\n","\n","gs://holoselecta_objectdetection/resnet50/train/packages/:\n","gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ctu_jncWrOIR","colab_type":"code","outputId":"f2b21b9a-8fc3-49bf-b9ac-351e04c6b21e","executionInfo":{"status":"error","timestamp":1558280315100,"user_tz":-120,"elapsed":35837,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":851}},"source":["import shutil\n","import os\n","\n","!mkdir test_model\n","!gsutil -m cp -r gs://holoselecta_objectdetection/resnet50/train/* test_model\n","\n","with open(\"test_model/README.md\".format(timestamp), \"+w\") as f:\n","  f.write(\"# Model Description  \\n\")\n","  f.write(\"Model: SSD, Resnet 50, Focal Point Network (FPN), Shared Box Predictor, (aka RetinaNet)  \\n\")\n","  f.write(\"Input Resolution: 640 x 640  \\n\")\n","  f.write(\"Classes: 47  \\n\")\n","  f.write(\"Training Images: _Automat  \\n\")\n","  f.write(\"Dataset Timestamp: 2019_5_18_15_41_18  \\n\")\n","  f.write(\"Training Steps: 7000  \\n\")\n","  f.write(\"Final mAP@.50IOU = 0.86 ; mAP@.75IOU = 0.78  \\n\")\n","  f.write(\"Max Score Steps: 7000\")\n","\n","shutil.copy(\"model/frozen_inference_graph.pb\", \"test_model/frozen_inference_graph.pb\")\n","shutil.copy(\"data/label_map.pbtxt\", \"test_model/label_map.pbtxt\")\n","shutil.copy(\"pipeline.config\", \"test_model/pipeline.config\")\n","shutil.copy(\"timestamp\", \"test_model/timestamp\")\n","\n","timestamp = \"2019_5_19_17_37_00\"\n","shutil.copytree(\"test_model\", os.path.join(FLAGS_OD.model_dir, \"Good\", timestamp))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘test_model’: File exists\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-1766.data-00000-of-00001...\n","Copying gs://holoselecta_objectdetection/resnet50/train/events.out.tfevents.1558252346.cmle-training-11657413241799530257...\n","Copying gs://holoselecta_objectdetection/resnet50/train/checkpoint...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-1766.meta...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-3468.meta...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-1766.index...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-3468.data-00000-of-00001...\n","Copying gs://holoselecta_objectdetection/resnet50/train/graph.pbtxt...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-3468.index...\n","Copying gs://holoselecta_objectdetection/resnet50/train/label_map.pbtxt...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-5187.data-00000-of-00001...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-5187.index...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-5187.meta...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-6996.data-00000-of-00001...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-6996.index...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-6996.meta...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-7000.index...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-7000.data-00000-of-00001...\n","Copying gs://holoselecta_objectdetection/resnet50/train/model.ckpt-7000.meta...\n","Copying gs://holoselecta_objectdetection/resnet50/train/timestamp...\n","Copying gs://holoselecta_objectdetection/resnet50/train/eval_0/events.out.tfevents.1558253017.cmle-training-11657413241799530257...\n","Copying gs://holoselecta_objectdetection/resnet50/train/export/Servo/1558254846/saved_model.pb...\n","Copying gs://holoselecta_objectdetection/resnet50/train/export/Servo/1558254846/variables/variables.data-00000-of-00001...\n","Copying gs://holoselecta_objectdetection/resnet50/train/export/Servo/1558254846/variables/variables.index...\n","Copying gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/object_detection-0.1.tar.gz...\n","Copying gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/pycocotools-2.0.tar.gz...\n","Copying gs://holoselecta_objectdetection/resnet50/train/packages/223573dc80e32687fc96e1d16e2534b6e7e4de78cf16292a7ffaf49fb0bc7d7d/slim-0.1.tar.gz...\n"],"name":"stdout"},{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-4f86e8ad62ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2019_5_19_17_37_00\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS_OD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Good\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mignored_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/gdrive/My Drive/Masterarbeit/ObjectDetection/Models/Good/2019_5_19_17_37_00'"]}]},{"cell_type":"code","metadata":{"id":"b6EISclNdjKT","colab_type":"code","colab":{}},"source":["!gsutil -m rm -r gs://holoselecta_objectdetection_2/train/*\n","!gsutil -m rm -r gs://holoselecta_objectdetection_2/data/*"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CrlE9n3JMql","colab_type":"text"},"source":["# Tensorboard"]},{"cell_type":"code","metadata":{"id":"tsMgLMxEftip","colab_type":"code","colab":{}},"source":["class FLAGS_TB:\n","  # a temporary folder to run tensorboard on, doesn't seem to run on a Gdrive mounted folder\n","  tmp_graph_dir = \"tmp_graph\"\n","  \n","  # how many images fit horizontally in an image mosaic\n","  tb_mosaic_width = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPG-ZvT_Y3zN","colab_type":"code","outputId":"da745044-30cd-4371-c49e-69f852662b6d","executionInfo":{"status":"ok","timestamp":1548234911547,"user_tz":-60,"elapsed":533,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import shutil\n","import os\n","\n","if os.path.exists(FLAGS_TB.tmp_graph_dir):\n","  print(\"delete dir:\")\n","  shutil.rmtree(FLAGS_TB.tmp_graph_dir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["delete dir:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pzcSrjJ6pRB9","colab_type":"code","outputId":"212bed05-fd2d-4b6d-d85b-09e1bcb86ac8","executionInfo":{"status":"ok","timestamp":1548235000484,"user_tz":-60,"elapsed":6125,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import shutil\n","\n","print(\"copy dir:\")\n","shutil.copytree(\"gdrive/My Drive/Masterarbeit/ObjectDetection/Models/2019_1_23_9_13_50\" ,FLAGS_TB.tmp_graph_dir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["copy dir:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'tmp_graph'"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"MVN3DrVnJLvi","colab_type":"code","outputId":"3454911b-c5c3-45e6-8da2-8434cad6770f","executionInfo":{"status":"ok","timestamp":1548224869412,"user_tz":-60,"elapsed":15990,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["#!pip install tensorboardcolab\n","from tensorboardcolab import TensorBoardColab\n","\n","tbc = TensorBoardColab(graph_path=FLAGS_TB.tmp_graph_dir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","http://1d54274a.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vxYtQzm4f2im","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}