{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ObjectDetection_Colab.ipynb","version":"0.3.2","provenance":[{"file_id":"1cwe49p-MdzTUCIw2bNFWZzCd13bGhpHm","timestamp":1548247326784},{"file_id":"1QEhG_598QVfIHzrHkBlW5Vr-FDC_Sap3","timestamp":1547824581824},{"file_id":"1R5DRV991c3xzXP1UTi2UenaTe7_Mc4zz","timestamp":1547032224712}],"collapsed_sections":["P4zwYJmzzHrc"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"F_GEUYwohHoq","colab_type":"text"},"source":["# Mount Google Drive to access files"]},{"cell_type":"markdown","metadata":{"id":"W16u76U3kZuo","colab_type":"text"},"source":["---\n","# Imports & Config  "]},{"cell_type":"markdown","metadata":{"id":"cSVKRj-Y_FML","colab_type":"text"},"source":["## Config"]},{"cell_type":"code","metadata":{"id":"MN0GUp9P_Iwi","colab_type":"code","colab":{}},"source":["import os\n","\n","base_dir = \"/content/gdrive/My Drive/Masterarbeit\"\n","object_detection_dir = os.path.join(base_dir, \"ObjectDetection\")\n","image_classification = os.path.join(base_dir, \"ImageClassification\")\n","\n","classes_dict_file = object_detection_dir + \"/classes.pkl\"\n","objects_dict_file = object_detection_dir + \"/objects.pkl\"\n","images_dict_file = object_detection_dir + \"/images.pkl\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KnV_yYQf5oyf","colab_type":"text"},"source":["## Check to GPU"]},{"cell_type":"code","metadata":{"id":"Pst5N5_NhkuT","colab_type":"code","outputId":"650c51a5-40a9-4bc4-c7e3-5979b09c6d62","executionInfo":{"status":"ok","timestamp":1559245131921,"user_tz":-120,"elapsed":3235,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":31}},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.13.1\n","Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1NihqGcD55V7","colab_type":"text"},"source":["## Mount GDrive"]},{"cell_type":"code","metadata":{"id":"MJHLlGTNgyM3","colab_type":"code","outputId":"78174dea-71a1-4cfb-b80d-1e0cfd92c66e","executionInfo":{"status":"ok","timestamp":1560714440373,"user_tz":-120,"elapsed":21097,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mFvtKHS-mQw0","colab_type":"code","colab":{}},"source":["from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQGn644UmP_S","colab_type":"code","outputId":"496980a5-4020-4965-956c-48e851edc14e","executionInfo":{"status":"ok","timestamp":1560714483117,"user_tz":-120,"elapsed":3280,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":117}},"source":["!gcloud config set project objectdetection-229309"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Updated property [core/project].\n","\n","\n","To take a quick anonymous survey, run:\n","  $ gcloud alpha survey\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-mbmvCGksZxk","colab_type":"text"},"source":["## Import TF"]},{"cell_type":"code","metadata":{"id":"QCw9zqxdsexx","colab_type":"code","outputId":"e5aba944-d195-4e1a-c69e-2be281c68bf9","executionInfo":{"status":"ok","timestamp":1560714514466,"user_tz":-120,"elapsed":30733,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":1003}},"source":["!git clone https://github.com/tensorflow/models.git /content/tf\n","!cd /content/tf/research; protoc object_detection/protos/*.proto --python_out=.\n","!cd /content/tf/research; export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim; python /content/tf/research/object_detection/builders/model_builder_test.py"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Cloning into '/content/tf'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 27714 (delta 0), reused 1 (delta 0), pack-reused 27708\u001b[K\n","Receiving objects: 100% (27714/27714), 509.12 MiB | 36.05 MiB/s, done.\n","Resolving deltas: 100% (16973/16973), done.\n","Checking out files: 100% (2998/2998), done.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0616 19:48:32.287679 140408731981696 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0616 19:48:32.502752 140408731981696 deprecation_wrapper.py:119] From /content/tf/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0616 19:48:32.552107 140408731981696 deprecation_wrapper.py:119] From /content/tf/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","Running tests under Python 3.6.7: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 16 tests in 0.225s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kga44qEusfFl","colab_type":"text"},"source":["## Defines"]},{"cell_type":"code","metadata":{"id":"m1KyzLKEslxU","colab_type":"code","outputId":"8ee42949-c7a9-4de2-db0a-ab6320cc63ee","executionInfo":{"status":"ok","timestamp":1560714519460,"user_tz":-120,"elapsed":3018,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":253}},"source":["import os\n","import sys\n","\n","# For running inference on the TF-Hub module.\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","# For downloading the image.\n","#import matplotlib.pyplot as plt\n","#import tempfile\n","#from six.moves.urllib.request import urlopen\n","#from six import BytesIO\n","\n","# For drawing onto the image.\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageColor\n","from PIL import ImageDraw\n","from PIL import ImageFont\n","from PIL import ImageOps\n","\n","import cv2\n","\n","# For measuring the inference time.\n","from datetime import datetime\n","\n","#for xml parsing\n","from bs4 import BeautifulSoup\n","\n","#...\n","sys.path.append('tf/research')\n","sys.path.append('tf/research/slim')\n","from object_detection.utils import dataset_util, config_util\n","from object_detection import model_main"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0616 19:48:38.829461 139855874557824 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0616 19:48:38.858706 139855874557824 deprecation_wrapper.py:119] From tf/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0616 19:48:38.872318 139855874557824 deprecation_wrapper.py:119] From tf/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-Yy4BYmos0-Q","colab_type":"code","colab":{}},"source":["class FLAGS_OD:\n","  image_dir = os.path.join(object_detection_dir, \"Images\")\n","  \n","  #tf records directory\n","  tf_records_dir = os.path.join(object_detection_dir, \"TFRecords\")\n","  #label_map directory\n","  label_map_dir = os.path.join(object_detection_dir, \"LabelMaps\")\n","  \n","  #class level to be considered\n","  class_level = [0,1]\n","  #how often the class of an object needs to occure to be considered\n","  min_class_occurence = 20\n","  \n","  #dataset split\n","  testing_percentage = 0\n","  validation_percentage = 10\n","  \n","  #pipeline config\n","  pipeline_config_dir = os.path.join(object_detection_dir, \"ConfigFiles\")\n","  \n","  #model checkpoints\n","  model_checkpoint_dir = os.path.join(object_detection_dir, \"ModelCheckpoints\")\n","  model_dir = os.path.join(object_detection_dir,\"Models\")\n","  \n","  #cloud configs\n","  cloud_config_dir = os.path.join(object_detection_dir, \"CloudConfigFiles\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsiDJktvvgw1","colab_type":"text"},"source":["# Train Setup"]},{"cell_type":"markdown","metadata":{"id":"1LVHST726PEg","colab_type":"text"},"source":["## Copy Data\n"]},{"cell_type":"code","metadata":{"id":"ALgoh3PQ_2KE","colab_type":"code","outputId":"65b613ca-5ab9-4766-f0ff-2bef635fadb4","executionInfo":{"status":"ok","timestamp":1559168102051,"user_tz":-120,"elapsed":20133,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":401}},"source":["!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","!tar -xvf faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","!rm faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","!mv faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-05-29 22:14:42--  http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.31.176, 2404:6800:4004:80c::2010\n","Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.31.176|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 672221478 (641M) [application/x-tar]\n","Saving to: ‘faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz’\n","\n","faster_rcnn_incepti 100%[===================>] 641.08M   138MB/s    in 4.6s    \n","\n","2019-05-29 22:14:47 (138 MB/s) - ‘faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz’ saved [672221478/672221478]\n","\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt.index\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/checkpoint\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/pipeline.config\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt.data-00000-of-00001\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt.meta\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model/\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model/saved_model.pb\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/saved_model/variables/\n","faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/frozen_inference_graph.pb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7b7-6zrNqQ05","colab_type":"code","colab":{}},"source":["!gsutil -m cp model/* gs://holoselecta_objectdetection/inception/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNCvic25q8Xt","colab_type":"code","outputId":"d68f8961-14f8-4cbf-f852-efd88a84df48","executionInfo":{"status":"ok","timestamp":1559041420118,"user_tz":-120,"elapsed":8206,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["#!gsutil cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/LabelMaps/2019_5_28_9_24_26.pbtxt gs://holoselecta_objectdetection/holoselecta/data/label_map.pbtxt\n","!gsutil cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/TFRecords/2019_5_28_9_24_26_test_960_100.record gs://holoselecta_objectdetection/holoselecta/data/val.record\n","!gsutil cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/TFRecords/2019_5_28_9_24_26_train_960_100.record gs://holoselecta_objectdetection/holoselecta/data/train.record"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Copying file:///content/gdrive/My Drive/Masterarbeit/ObjectDetection/TFRecords/2019_5_28_9_24_26_test_640_100.record [Content-Type=application/octet-stream]...\n","- [1 files][ 12.6 MiB/ 12.6 MiB]                                                \n","Operation completed over 1 objects/12.6 MiB.                                     \n","Copying file:///content/gdrive/My Drive/Masterarbeit/ObjectDetection/TFRecords/2019_5_28_9_24_26_train_640_100.record [Content-Type=application/octet-stream]...\n","\\\n","Operation completed over 1 objects/47.1 MiB.                                     \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y2ik-yYLticj","colab_type":"code","colab":{}},"source":["!cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/ConfigFiles/faster_rcnn_inception_resnet_v2_atrous_holoselecta.config pipeline.config"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UfmdlF0vOie","colab_type":"text"},"source":["# Run"]},{"cell_type":"markdown","metadata":{"id":"M5SIPqTzzFRw","colab_type":"text"},"source":["## adapted"]},{"cell_type":"code","metadata":{"id":"rSKMDhIhDuuO","colab_type":"code","colab":{}},"source":["# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","r\"\"\"Constructs model, inputs, and training environment.\"\"\"\n","\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import copy\n","import functools\n","import os\n","\n","import tensorflow as tf\n","\n","from object_detection import eval_util\n","from object_detection import exporter as exporter_lib\n","from object_detection import inputs\n","from object_detection.builders import graph_rewriter_builder\n","from object_detection.builders import model_builder\n","from object_detection.builders import optimizer_builder\n","from object_detection.core import standard_fields as fields\n","from object_detection.utils import config_util\n","from object_detection.utils import label_map_util\n","from object_detection.utils import shape_utils\n","from object_detection.utils import variables_helper\n","from object_detection.utils import visualization_utils as vis_utils\n","\n","# A map of names to methods that help build the model.\n","MODEL_BUILD_UTIL_MAP = {\n","    'get_configs_from_pipeline_file':\n","        config_util.get_configs_from_pipeline_file,\n","    'create_pipeline_proto_from_configs':\n","        config_util.create_pipeline_proto_from_configs,\n","    'merge_external_params_with_configs':\n","        config_util.merge_external_params_with_configs,\n","    'create_train_input_fn':\n","        inputs.create_train_input_fn,\n","    'create_eval_input_fn':\n","        inputs.create_eval_input_fn,\n","    'create_predict_input_fn':\n","        inputs.create_predict_input_fn,\n","}\n","\n","\n","def _prepare_groundtruth_for_eval(detection_model, class_agnostic,\n","                                  max_number_of_boxes):\n","  \"\"\"Extracts groundtruth data from detection_model and prepares it for eval.\n","  Args:\n","    detection_model: A `DetectionModel` object.\n","    class_agnostic: Whether the detections are class_agnostic.\n","    max_number_of_boxes: Max number of groundtruth boxes.\n","  Returns:\n","    A tuple of:\n","    groundtruth: Dictionary with the following fields:\n","      'groundtruth_boxes': [batch_size, num_boxes, 4] float32 tensor of boxes,\n","        in normalized coordinates.\n","      'groundtruth_classes': [batch_size, num_boxes] int64 tensor of 1-indexed\n","        classes.\n","      'groundtruth_masks': 4D float32 tensor of instance masks (if provided in\n","        groundtruth)\n","      'groundtruth_is_crowd': [batch_size, num_boxes] bool tensor indicating\n","        is_crowd annotations (if provided in groundtruth).\n","      'num_groundtruth_boxes': [batch_size] tensor containing the maximum number\n","        of groundtruth boxes per image..\n","    class_agnostic: Boolean indicating whether detections are class agnostic.\n","  \"\"\"\n","  input_data_fields = fields.InputDataFields()\n","  groundtruth_boxes = tf.stack(\n","      detection_model.groundtruth_lists(fields.BoxListFields.boxes))\n","  groundtruth_boxes_shape = tf.shape(groundtruth_boxes)\n","  # For class-agnostic models, groundtruth one-hot encodings collapse to all\n","  # ones.\n","  if class_agnostic:\n","    groundtruth_classes_one_hot = tf.ones(\n","        [groundtruth_boxes_shape[0], groundtruth_boxes_shape[1], 1])\n","  else:\n","    groundtruth_classes_one_hot = tf.stack(\n","        detection_model.groundtruth_lists(fields.BoxListFields.classes))\n","  label_id_offset = 1  # Applying label id offset (b/63711816)\n","  groundtruth_classes = (\n","      tf.argmax(groundtruth_classes_one_hot, axis=2) + label_id_offset)\n","  groundtruth = {\n","      input_data_fields.groundtruth_boxes: groundtruth_boxes,\n","      input_data_fields.groundtruth_classes: groundtruth_classes\n","  }\n","  if detection_model.groundtruth_has_field(fields.BoxListFields.masks):\n","    groundtruth[input_data_fields.groundtruth_instance_masks] = tf.stack(\n","        detection_model.groundtruth_lists(fields.BoxListFields.masks))\n","\n","  if detection_model.groundtruth_has_field(fields.BoxListFields.is_crowd):\n","    groundtruth[input_data_fields.groundtruth_is_crowd] = tf.stack(\n","        detection_model.groundtruth_lists(fields.BoxListFields.is_crowd))\n","\n","  groundtruth[input_data_fields.num_groundtruth_boxes] = (\n","      tf.tile([max_number_of_boxes], multiples=[groundtruth_boxes_shape[0]]))\n","  return groundtruth\n","\n","\n","def unstack_batch(tensor_dict, unpad_groundtruth_tensors=True):\n","  \"\"\"Unstacks all tensors in `tensor_dict` along 0th dimension.\n","  Unstacks tensor from the tensor dict along 0th dimension and returns a\n","  tensor_dict containing values that are lists of unstacked, unpadded tensors.\n","  Tensors in the `tensor_dict` are expected to be of one of the three shapes:\n","  1. [batch_size]\n","  2. [batch_size, height, width, channels]\n","  3. [batch_size, num_boxes, d1, d2, ... dn]\n","  When unpad_groundtruth_tensors is set to true, unstacked tensors of form 3\n","  above are sliced along the `num_boxes` dimension using the value in tensor\n","  field.InputDataFields.num_groundtruth_boxes.\n","  Note that this function has a static list of input data fields and has to be\n","  kept in sync with the InputDataFields defined in core/standard_fields.py\n","  Args:\n","    tensor_dict: A dictionary of batched groundtruth tensors.\n","    unpad_groundtruth_tensors: Whether to remove padding along `num_boxes`\n","      dimension of the groundtruth tensors.\n","  Returns:\n","    A dictionary where the keys are from fields.InputDataFields and values are\n","    a list of unstacked (optionally unpadded) tensors.\n","  Raises:\n","    ValueError: If unpad_tensors is True and `tensor_dict` does not contain\n","      `num_groundtruth_boxes` tensor.\n","  \"\"\"\n","  unbatched_tensor_dict = {\n","      key: tf.unstack(tensor) for key, tensor in tensor_dict.items()\n","  }\n","  if unpad_groundtruth_tensors:\n","    if (fields.InputDataFields.num_groundtruth_boxes not in\n","        unbatched_tensor_dict):\n","      raise ValueError('`num_groundtruth_boxes` not found in tensor_dict. '\n","                       'Keys available: {}'.format(\n","                           unbatched_tensor_dict.keys()))\n","    unbatched_unpadded_tensor_dict = {}\n","    unpad_keys = set([\n","        # List of input data fields that are padded along the num_boxes\n","        # dimension. This list has to be kept in sync with InputDataFields in\n","        # standard_fields.py.\n","        fields.InputDataFields.groundtruth_instance_masks,\n","        fields.InputDataFields.groundtruth_classes,\n","        fields.InputDataFields.groundtruth_boxes,\n","        fields.InputDataFields.groundtruth_keypoints,\n","        fields.InputDataFields.groundtruth_group_of,\n","        fields.InputDataFields.groundtruth_difficult,\n","        fields.InputDataFields.groundtruth_is_crowd,\n","        fields.InputDataFields.groundtruth_area,\n","        fields.InputDataFields.groundtruth_weights\n","    ]).intersection(set(unbatched_tensor_dict.keys()))\n","\n","    for key in unpad_keys:\n","      unpadded_tensor_list = []\n","      for num_gt, padded_tensor in zip(\n","          unbatched_tensor_dict[fields.InputDataFields.num_groundtruth_boxes],\n","          unbatched_tensor_dict[key]):\n","        tensor_shape = shape_utils.combined_static_and_dynamic_shape(\n","            padded_tensor)\n","        slice_begin = tf.zeros([len(tensor_shape)], dtype=tf.int32)\n","        slice_size = tf.stack(\n","            [num_gt] + [-1 if dim is None else dim for dim in tensor_shape[1:]])\n","        unpadded_tensor = tf.slice(padded_tensor, slice_begin, slice_size)\n","        unpadded_tensor_list.append(unpadded_tensor)\n","      unbatched_unpadded_tensor_dict[key] = unpadded_tensor_list\n","    unbatched_tensor_dict.update(unbatched_unpadded_tensor_dict)\n","\n","  return unbatched_tensor_dict\n","\n","\n","def create_model_fn(detection_model_fn, configs, hparams, use_tpu=False):\n","  \"\"\"Creates a model function for `Estimator`.\n","  Args:\n","    detection_model_fn: Function that returns a `DetectionModel` instance.\n","    configs: Dictionary of pipeline config objects.\n","    hparams: `HParams` object.\n","    use_tpu: Boolean indicating whether model should be constructed for\n","        use on TPU.\n","  Returns:\n","    `model_fn` for `Estimator`.\n","  \"\"\"\n","  train_config = configs['train_config']\n","  eval_input_config = configs['eval_input_config']\n","  eval_config = configs['eval_config']\n","\n","  def model_fn(features, labels, mode, params=None):\n","    \"\"\"Constructs the object detection model.\n","    Args:\n","      features: Dictionary of feature tensors, returned from `input_fn`.\n","      labels: Dictionary of groundtruth tensors if mode is TRAIN or EVAL,\n","        otherwise None.\n","      mode: Mode key from tf.estimator.ModeKeys.\n","      params: Parameter dictionary passed from the estimator.\n","    Returns:\n","      An `EstimatorSpec` that encapsulates the model and its serving\n","        configurations.\n","    \"\"\"\n","    params = params or {}\n","    total_loss, train_op, detections, export_outputs = None, None, None, None\n","    is_training = mode == tf.estimator.ModeKeys.TRAIN\n","\n","    # Make sure to set the Keras learning phase. True during training,\n","    # False for inference.\n","    tf.keras.backend.set_learning_phase(is_training)\n","    detection_model = detection_model_fn(\n","        is_training=is_training, add_summaries=(not use_tpu))\n","    scaffold_fn = None\n","\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","      labels = unstack_batch(\n","          labels,\n","          unpad_groundtruth_tensors=train_config.unpad_groundtruth_tensors)\n","    elif mode == tf.estimator.ModeKeys.EVAL:\n","      # For evaling on train data, it is necessary to check whether groundtruth\n","      # must be unpadded.\n","      boxes_shape = (\n","          labels[fields.InputDataFields.groundtruth_boxes].get_shape()\n","          .as_list())\n","      unpad_groundtruth_tensors = boxes_shape[1] is not None and not use_tpu\n","      labels = unstack_batch(\n","          labels, unpad_groundtruth_tensors=unpad_groundtruth_tensors)\n","\n","    if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n","      gt_boxes_list = labels[fields.InputDataFields.groundtruth_boxes]\n","      gt_classes_list = labels[fields.InputDataFields.groundtruth_classes]\n","      gt_masks_list = None\n","      if fields.InputDataFields.groundtruth_instance_masks in labels:\n","        gt_masks_list = labels[\n","            fields.InputDataFields.groundtruth_instance_masks]\n","      gt_keypoints_list = None\n","      if fields.InputDataFields.groundtruth_keypoints in labels:\n","        gt_keypoints_list = labels[fields.InputDataFields.groundtruth_keypoints]\n","      gt_weights_list = None\n","      if fields.InputDataFields.groundtruth_weights in labels:\n","        gt_weights_list = labels[fields.InputDataFields.groundtruth_weights]\n","      gt_confidences_list = None\n","      if fields.InputDataFields.groundtruth_confidences in labels:\n","        gt_confidences_list = labels[\n","            fields.InputDataFields.groundtruth_confidences]\n","      gt_is_crowd_list = None\n","      if fields.InputDataFields.groundtruth_is_crowd in labels:\n","        gt_is_crowd_list = labels[fields.InputDataFields.groundtruth_is_crowd]\n","      detection_model.provide_groundtruth(\n","          groundtruth_boxes_list=gt_boxes_list,\n","          groundtruth_classes_list=gt_classes_list,\n","          groundtruth_confidences_list=gt_confidences_list,\n","          groundtruth_masks_list=gt_masks_list,\n","          groundtruth_keypoints_list=gt_keypoints_list,\n","          groundtruth_weights_list=gt_weights_list,\n","          groundtruth_is_crowd_list=gt_is_crowd_list)\n","\n","    preprocessed_images = features[fields.InputDataFields.image]\n","    if use_tpu and train_config.use_bfloat16:\n","      with tf.contrib.tpu.bfloat16_scope():\n","        prediction_dict = detection_model.predict(\n","            preprocessed_images,\n","            features[fields.InputDataFields.true_image_shape])\n","        for k, v in prediction_dict.items():\n","          if v.dtype == tf.bfloat16:\n","            prediction_dict[k] = tf.cast(v, tf.float32)\n","    else:\n","      prediction_dict = detection_model.predict(\n","          preprocessed_images,\n","          features[fields.InputDataFields.true_image_shape])\n","    if mode in (tf.estimator.ModeKeys.EVAL, tf.estimator.ModeKeys.PREDICT):\n","      detections = detection_model.postprocess(\n","          prediction_dict, features[fields.InputDataFields.true_image_shape])\n","\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","      if train_config.fine_tune_checkpoint and hparams.load_pretrained:\n","        if not train_config.fine_tune_checkpoint_type:\n","          # train_config.from_detection_checkpoint field is deprecated. For\n","          # backward compatibility, set train_config.fine_tune_checkpoint_type\n","          # based on train_config.from_detection_checkpoint.\n","          if train_config.from_detection_checkpoint:\n","            train_config.fine_tune_checkpoint_type = 'detection'\n","          else:\n","            train_config.fine_tune_checkpoint_type = 'classification'\n","        asg_map = detection_model.restore_map(\n","            fine_tune_checkpoint_type=train_config.fine_tune_checkpoint_type,\n","            load_all_detection_checkpoint_vars=(\n","                train_config.load_all_detection_checkpoint_vars))\n","        available_var_map = (\n","            variables_helper.get_variables_available_in_checkpoint(\n","                asg_map,\n","                train_config.fine_tune_checkpoint,\n","                include_global_step=False))\n","        if use_tpu:\n","\n","          def tpu_scaffold():\n","            tf.train.init_from_checkpoint(train_config.fine_tune_checkpoint,\n","                                          available_var_map)\n","            return tf.train.Scaffold()\n","\n","          scaffold_fn = tpu_scaffold\n","        else:\n","          tf.train.init_from_checkpoint(train_config.fine_tune_checkpoint,\n","                                        available_var_map)\n","\n","    if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n","      losses_dict = detection_model.loss(\n","          prediction_dict, features[fields.InputDataFields.true_image_shape])\n","      losses = [loss_tensor for loss_tensor in losses_dict.values()]\n","      if train_config.add_regularization_loss:\n","        regularization_losses = detection_model.regularization_losses()\n","        if regularization_losses:\n","          regularization_loss = tf.add_n(\n","              regularization_losses, name='regularization_loss')\n","          losses.append(regularization_loss)\n","          losses_dict['Loss/regularization_loss'] = regularization_loss\n","      total_loss = tf.add_n(losses, name='total_loss')\n","      losses_dict['Loss/total_loss'] = total_loss\n","\n","      if 'graph_rewriter_config' in configs:\n","        graph_rewriter_fn = graph_rewriter_builder.build(\n","            configs['graph_rewriter_config'], is_training=is_training)\n","        graph_rewriter_fn()\n","\n","      # TODO(rathodv): Stop creating optimizer summary vars in EVAL mode once we\n","      # can write learning rate summaries on TPU without host calls.\n","      global_step = tf.train.get_or_create_global_step()\n","      training_optimizer, optimizer_summary_vars = optimizer_builder.build(\n","          train_config.optimizer)\n","\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","      if use_tpu:\n","        training_optimizer = tf.contrib.tpu.CrossShardOptimizer(\n","            training_optimizer)\n","\n","      # Optionally freeze some layers by setting their gradients to be zero.\n","      trainable_variables = None\n","      include_variables = (\n","          train_config.update_trainable_variables\n","          if train_config.update_trainable_variables else None)\n","      exclude_variables = (\n","          train_config.freeze_variables\n","          if train_config.freeze_variables else None)\n","      trainable_variables = tf.contrib.framework.filter_variables(\n","          tf.trainable_variables(),\n","          include_patterns=include_variables,\n","          exclude_patterns=exclude_variables)\n","\n","      clip_gradients_value = None\n","      if train_config.gradient_clipping_by_norm > 0:\n","        clip_gradients_value = train_config.gradient_clipping_by_norm\n","\n","      if not use_tpu:\n","        for var in optimizer_summary_vars:\n","          tf.summary.scalar(var.op.name, var)\n","      summaries = [] if use_tpu else None\n","      if train_config.summarize_gradients:\n","        summaries = ['gradients', 'gradient_norm', 'global_gradient_norm']\n","      train_op = tf.contrib.layers.optimize_loss(\n","          loss=total_loss,\n","          global_step=global_step,\n","          learning_rate=None,\n","          clip_gradients=clip_gradients_value,\n","          optimizer=training_optimizer,\n","          update_ops=detection_model.updates(),\n","          variables=trainable_variables,\n","          summaries=summaries,\n","          name='')  # Preventing scope prefix on all variables.\n","\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","      exported_output = exporter_lib.add_output_tensor_nodes(detections)\n","      export_outputs = {\n","          tf.saved_model.signature_constants.PREDICT_METHOD_NAME:\n","              tf.estimator.export.PredictOutput(exported_output)\n","      }\n","\n","    eval_metric_ops = None\n","    scaffold = None\n","    if mode == tf.estimator.ModeKeys.EVAL:\n","      class_agnostic = (\n","          fields.DetectionResultFields.detection_classes not in detections)\n","      groundtruth = _prepare_groundtruth_for_eval(\n","          detection_model, class_agnostic,\n","          eval_input_config.max_number_of_boxes)\n","      use_original_images = fields.InputDataFields.original_image in features\n","      if use_original_images:\n","        eval_images = features[fields.InputDataFields.original_image]\n","        true_image_shapes = tf.slice(\n","            features[fields.InputDataFields.true_image_shape], [0, 0], [-1, 3])\n","        original_image_spatial_shapes = features[fields.InputDataFields\n","                                                 .original_image_spatial_shape]\n","      else:\n","        eval_images = features[fields.InputDataFields.image]\n","        true_image_shapes = None\n","        original_image_spatial_shapes = None\n","\n","      eval_dict = eval_util.result_dict_for_batched_example(\n","          eval_images,\n","          features[inputs.HASH_KEY],\n","          detections,\n","          groundtruth,\n","          class_agnostic=class_agnostic,\n","          scale_to_absolute=True,\n","          original_image_spatial_shapes=original_image_spatial_shapes,\n","          true_image_shapes=true_image_shapes)\n","\n","      if class_agnostic:\n","        category_index = label_map_util.create_class_agnostic_category_index()\n","      else:\n","        category_index = label_map_util.create_category_index_from_labelmap(\n","            eval_input_config.label_map_path)\n","      vis_metric_ops = None\n","      if not use_tpu and use_original_images:\n","        eval_metric_op_vis = vis_utils.VisualizeSingleFrameDetections(\n","            category_index,\n","            max_examples_to_draw=eval_config.num_visualizations,\n","            max_boxes_to_draw=eval_config.max_num_boxes_to_visualize,\n","            min_score_thresh=eval_config.min_score_threshold,\n","            use_normalized_coordinates=False)\n","        vis_metric_ops = eval_metric_op_vis.get_estimator_eval_metric_ops(\n","            eval_dict)\n","\n","      # Eval metrics on a single example.\n","      eval_metric_ops = eval_util.get_eval_metric_ops_for_evaluators(\n","          eval_config, list(category_index.values()), eval_dict)\n","      for loss_key, loss_tensor in iter(losses_dict.items()):\n","        eval_metric_ops[loss_key] = tf.metrics.mean(loss_tensor)\n","      for var in optimizer_summary_vars:\n","        eval_metric_ops[var.op.name] = (var, tf.no_op())\n","      if vis_metric_ops is not None:\n","        eval_metric_ops.update(vis_metric_ops)\n","      eval_metric_ops = {str(k): v for k, v in eval_metric_ops.items()}\n","\n","      if eval_config.use_moving_averages:\n","        variable_averages = tf.train.ExponentialMovingAverage(0.0)\n","        variables_to_restore = variable_averages.variables_to_restore()\n","        keep_checkpoint_every_n_hours = (\n","            train_config.keep_checkpoint_every_n_hours)\n","        saver = tf.train.Saver(\n","            variables_to_restore,\n","            keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n","        scaffold = tf.train.Scaffold(saver=saver)\n","\n","    # EVAL executes on CPU, so use regular non-TPU EstimatorSpec.\n","    if use_tpu and mode != tf.estimator.ModeKeys.EVAL:\n","      return tf.contrib.tpu.TPUEstimatorSpec(\n","          mode=mode,\n","          scaffold_fn=scaffold_fn,\n","          predictions=detections,\n","          loss=total_loss,\n","          train_op=train_op,\n","          eval_metrics=eval_metric_ops,\n","          export_outputs=export_outputs)\n","    else:\n","      if scaffold is None:\n","        keep_checkpoint_every_n_hours = (\n","            train_config.keep_checkpoint_every_n_hours)\n","        saver = tf.train.Saver(\n","            sharded=True,\n","            keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours,\n","            save_relative_paths=True)\n","        tf.add_to_collection(tf.GraphKeys.SAVERS, saver)\n","        scaffold = tf.train.Scaffold(saver=saver)\n","      return tf.estimator.EstimatorSpec(\n","          mode=mode,\n","          predictions=detections,\n","          loss=total_loss,\n","          train_op=train_op,\n","          eval_metric_ops=eval_metric_ops,\n","          export_outputs=export_outputs,\n","          scaffold=scaffold)\n","\n","  return model_fn\n","\n","\n","def create_estimator_and_inputs(run_config,\n","                                hparams,\n","                                pipeline_config_path,\n","                                config_override=None,\n","                                train_steps=None,\n","                                sample_1_of_n_eval_examples=1,\n","                                sample_1_of_n_eval_on_train_examples=1,\n","                                model_fn_creator=create_model_fn,\n","                                use_tpu_estimator=False,\n","                                use_tpu=False,\n","                                num_shards=1,\n","                                params=None,\n","                                override_eval_num_epochs=True,\n","                                save_final_config=False,\n","                                **kwargs):\n","  \"\"\"Creates `Estimator`, input functions, and steps.\n","  Args:\n","    run_config: A `RunConfig`.\n","    hparams: A `HParams`.\n","    pipeline_config_path: A path to a pipeline config file.\n","    config_override: A pipeline_pb2.TrainEvalPipelineConfig text proto to\n","      override the config from `pipeline_config_path`.\n","    train_steps: Number of training steps. If None, the number of training steps\n","      is set from the `TrainConfig` proto.\n","    sample_1_of_n_eval_examples: Integer representing how often an eval example\n","      should be sampled. If 1, will sample all examples.\n","    sample_1_of_n_eval_on_train_examples: Similar to\n","      `sample_1_of_n_eval_examples`, except controls the sampling of training\n","      data for evaluation.\n","    model_fn_creator: A function that creates a `model_fn` for `Estimator`.\n","      Follows the signature:\n","      * Args:\n","        * `detection_model_fn`: Function that returns `DetectionModel` instance.\n","        * `configs`: Dictionary of pipeline config objects.\n","        * `hparams`: `HParams` object.\n","      * Returns:\n","        `model_fn` for `Estimator`.\n","    use_tpu_estimator: Whether a `TPUEstimator` should be returned. If False,\n","      an `Estimator` will be returned.\n","    use_tpu: Boolean, whether training and evaluation should run on TPU. Only\n","      used if `use_tpu_estimator` is True.\n","    num_shards: Number of shards (TPU cores). Only used if `use_tpu_estimator`\n","      is True.\n","    params: Parameter dictionary passed from the estimator. Only used if\n","      `use_tpu_estimator` is True.\n","    override_eval_num_epochs: Whether to overwrite the number of epochs to\n","      1 for eval_input.\n","    save_final_config: Whether to save final config (obtained after applying\n","      overrides) to `estimator.model_dir`.\n","    **kwargs: Additional keyword arguments for configuration override.\n","  Returns:\n","    A dictionary with the following fields:\n","    'estimator': An `Estimator` or `TPUEstimator`.\n","    'train_input_fn': A training input function.\n","    'eval_input_fns': A list of all evaluation input functions.\n","    'eval_input_names': A list of names for each evaluation input.\n","    'eval_on_train_input_fn': An evaluation-on-train input function.\n","    'predict_input_fn': A prediction input function.\n","    'train_steps': Number of training steps. Either directly from input or from\n","      configuration.\n","  \"\"\"\n","  get_configs_from_pipeline_file = MODEL_BUILD_UTIL_MAP[\n","      'get_configs_from_pipeline_file']\n","  merge_external_params_with_configs = MODEL_BUILD_UTIL_MAP[\n","      'merge_external_params_with_configs']\n","  create_pipeline_proto_from_configs = MODEL_BUILD_UTIL_MAP[\n","      'create_pipeline_proto_from_configs']\n","  create_train_input_fn = MODEL_BUILD_UTIL_MAP['create_train_input_fn']\n","  create_eval_input_fn = MODEL_BUILD_UTIL_MAP['create_eval_input_fn']\n","  create_predict_input_fn = MODEL_BUILD_UTIL_MAP['create_predict_input_fn']\n","\n","  configs = get_configs_from_pipeline_file(pipeline_config_path,\n","                                           config_override=config_override)\n","  kwargs.update({\n","      'train_steps': train_steps,\n","      'sample_1_of_n_eval_examples': sample_1_of_n_eval_examples\n","  })\n","  if override_eval_num_epochs:\n","    kwargs.update({'eval_num_epochs': 1})\n","    tf.logging.warning(\n","        'Forced number of epochs for all eval validations to be 1.')\n","  configs = merge_external_params_with_configs(\n","      configs, hparams, kwargs_dict=kwargs)\n","  model_config = configs['model']\n","  train_config = configs['train_config']\n","  train_input_config = configs['train_input_config']\n","  eval_config = configs['eval_config']\n","  eval_input_configs = configs['eval_input_configs']\n","  eval_on_train_input_config = copy.deepcopy(train_input_config)\n","  eval_on_train_input_config.sample_1_of_n_examples = (\n","      sample_1_of_n_eval_on_train_examples)\n","  if override_eval_num_epochs and eval_on_train_input_config.num_epochs != 1:\n","    tf.logging.warning('Expected number of evaluation epochs is 1, but '\n","                       'instead encountered `eval_on_train_input_config'\n","                       '.num_epochs` = '\n","                       '{}. Overwriting `num_epochs` to 1.'.format(\n","                           eval_on_train_input_config.num_epochs))\n","    eval_on_train_input_config.num_epochs = 1\n","\n","  # update train_steps from config but only when non-zero value is provided\n","  if train_steps is None and train_config.num_steps != 0:\n","    train_steps = train_config.num_steps\n","\n","  detection_model_fn = functools.partial(\n","      model_builder.build, model_config=model_config)\n","\n","  # Create the input functions for TRAIN/EVAL/PREDICT.\n","  train_input_fn = create_train_input_fn(\n","      train_config=train_config,\n","      train_input_config=train_input_config,\n","      model_config=model_config)\n","  eval_input_fns = [\n","      create_eval_input_fn(\n","          eval_config=eval_config,\n","          eval_input_config=eval_input_config,\n","          model_config=model_config) for eval_input_config in eval_input_configs\n","  ]\n","  eval_input_names = [\n","      eval_input_config.name for eval_input_config in eval_input_configs\n","  ]\n","  eval_on_train_input_fn = create_eval_input_fn(\n","      eval_config=eval_config,\n","      eval_input_config=eval_on_train_input_config,\n","      model_config=model_config)\n","  predict_input_fn = create_predict_input_fn(\n","      model_config=model_config, predict_input_config=eval_input_configs[0])\n","\n","  export_to_tpu = hparams.get('export_to_tpu', False)\n","  tf.logging.info('create_estimator_and_inputs: use_tpu %s, export_to_tpu %s',\n","                  use_tpu, export_to_tpu)\n","  model_fn = model_fn_creator(detection_model_fn, configs, hparams, use_tpu)\n","  if use_tpu_estimator:\n","    estimator = tf.contrib.tpu.TPUEstimator(\n","        model_fn=model_fn,\n","        train_batch_size=train_config.batch_size,\n","        # For each core, only batch size 1 is supported for eval.\n","        eval_batch_size=num_shards * 1 if use_tpu else 1,\n","        use_tpu=use_tpu,\n","        config=run_config,\n","        # TODO(lzc): Remove conditional after CMLE moves to TF 1.9\n","        params=params if params else {})\n","  else:\n","    estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n","\n","  # Write the as-run pipeline config to disk.\n","  if run_config.is_chief and save_final_config:\n","    pipeline_config_final = create_pipeline_proto_from_configs(configs)\n","    config_util.save_pipeline_config(pipeline_config_final, estimator.model_dir)\n","\n","  return dict(\n","      estimator=estimator,\n","      train_input_fn=train_input_fn,\n","      eval_input_fns=eval_input_fns,\n","      eval_input_names=eval_input_names,\n","      eval_on_train_input_fn=eval_on_train_input_fn,\n","      predict_input_fn=predict_input_fn,\n","      train_steps=train_steps)\n","\n","\n","def create_train_and_eval_specs(train_input_fn,\n","                                eval_input_fns,\n","                                eval_on_train_input_fn,\n","                                predict_input_fn,\n","                                train_steps,\n","                                eval_on_train_data=False,\n","                                final_exporter_name='Servo',\n","                                eval_spec_names=None):\n","  \"\"\"Creates a `TrainSpec` and `EvalSpec`s.\n","  Args:\n","    train_input_fn: Function that produces features and labels on train data.\n","    eval_input_fns: A list of functions that produce features and labels on eval\n","      data.\n","    eval_on_train_input_fn: Function that produces features and labels for\n","      evaluation on train data.\n","    predict_input_fn: Function that produces features for inference.\n","    train_steps: Number of training steps.\n","    eval_on_train_data: Whether to evaluate model on training data. Default is\n","      False.\n","    final_exporter_name: String name given to `FinalExporter`.\n","    eval_spec_names: A list of string names for each `EvalSpec`.\n","  Returns:\n","    Tuple of `TrainSpec` and list of `EvalSpecs`. If `eval_on_train_data` is\n","    True, the last `EvalSpec` in the list will correspond to training data. The\n","    rest EvalSpecs in the list are evaluation datas.\n","  \"\"\"\n","  train_spec = tf.estimator.TrainSpec(\n","      input_fn=train_input_fn, max_steps=train_steps)\n","\n","  if eval_spec_names is None:\n","    eval_spec_names = [str(i) for i in range(len(eval_input_fns))]\n","\n","  eval_specs = []\n","  for index, (eval_spec_name, eval_input_fn) in enumerate(\n","      zip(eval_spec_names, eval_input_fns)):\n","    # Uses final_exporter_name as exporter_name for the first eval spec for\n","    # backward compatibility.\n","    if index == 0:\n","      exporter_name = final_exporter_name\n","    else:\n","      exporter_name = '{}_{}'.format(final_exporter_name, eval_spec_name)\n","    exporter = tf.estimator.FinalExporter(\n","        name=exporter_name, serving_input_receiver_fn=predict_input_fn)\n","    eval_specs.append(\n","        tf.estimator.EvalSpec(\n","            name=eval_spec_name,\n","            input_fn=eval_input_fn,\n","            steps=None,\n","            exporters=exporter,\n","            throttle_secs=FLAGS_OD.throttle_secs))\n","\n","  if eval_on_train_data:\n","    eval_specs.append(\n","        tf.estimator.EvalSpec(\n","            name='eval_on_train', input_fn=eval_on_train_input_fn, steps=None))\n","\n","  return train_spec, eval_specs\n","\n","\n","def continuous_eval(estimator, model_dir, input_fn, train_steps, name):\n","  \"\"\"Perform continuous evaluation on checkpoints written to a model directory.\n","  Args:\n","    estimator: Estimator object to use for evaluation.\n","    model_dir: Model directory to read checkpoints for continuous evaluation.\n","    input_fn: Input function to use for evaluation.\n","    train_steps: Number of training steps. This is used to infer the last\n","      checkpoint and stop evaluation loop.\n","    name: Namescope for eval summary.\n","  \"\"\"\n","\n","  def terminate_eval():\n","    tf.logging.info('Terminating eval after 180 seconds of no checkpoints')\n","    return True\n","\n","  for ckpt in tf.contrib.training.checkpoints_iterator(\n","      model_dir, min_interval_secs=180, timeout=None,\n","      timeout_fn=terminate_eval):\n","\n","    tf.logging.info('Starting Evaluation.')\n","    try:\n","      eval_results = estimator.evaluate(\n","          input_fn=input_fn, steps=None, checkpoint_path=ckpt, name=name)\n","      tf.logging.info('Eval results: %s' % eval_results)\n","\n","      # Terminate eval job when final checkpoint is reached\n","      current_step = int(os.path.basename(ckpt).split('-')[1])\n","      if current_step >= train_steps:\n","        tf.logging.info(\n","            'Evaluation finished after training step %d' % current_step)\n","        break\n","\n","    except tf.errors.NotFoundError:\n","      tf.logging.info(\n","          'Checkpoint %s no longer exists, skipping checkpoint' % ckpt)\n","\n","\n","def populate_experiment(run_config,\n","                        hparams,\n","                        pipeline_config_path,\n","                        train_steps=None,\n","                        eval_steps=None,\n","                        model_fn_creator=create_model_fn,\n","                        **kwargs):\n","  \"\"\"Populates an `Experiment` object.\n","  EXPERIMENT CLASS IS DEPRECATED. Please switch to\n","  tf.estimator.train_and_evaluate. As an example, see model_main.py.\n","  Args:\n","    run_config: A `RunConfig`.\n","    hparams: A `HParams`.\n","    pipeline_config_path: A path to a pipeline config file.\n","    train_steps: Number of training steps. If None, the number of training steps\n","      is set from the `TrainConfig` proto.\n","    eval_steps: Number of evaluation steps per evaluation cycle. If None, the\n","      number of evaluation steps is set from the `EvalConfig` proto.\n","    model_fn_creator: A function that creates a `model_fn` for `Estimator`.\n","      Follows the signature:\n","      * Args:\n","        * `detection_model_fn`: Function that returns `DetectionModel` instance.\n","        * `configs`: Dictionary of pipeline config objects.\n","        * `hparams`: `HParams` object.\n","      * Returns:\n","        `model_fn` for `Estimator`.\n","    **kwargs: Additional keyword arguments for configuration override.\n","  Returns:\n","    An `Experiment` that defines all aspects of training, evaluation, and\n","    export.\n","  \"\"\"\n","  tf.logging.warning('Experiment is being deprecated. Please use '\n","                     'tf.estimator.train_and_evaluate(). See model_main.py for '\n","                     'an example.')\n","  train_and_eval_dict = create_estimator_and_inputs(\n","      run_config,\n","      hparams,\n","      pipeline_config_path,\n","      train_steps=train_steps,\n","      eval_steps=eval_steps,\n","      model_fn_creator=model_fn_creator,\n","      save_final_config=True,\n","      **kwargs)\n","  estimator = train_and_eval_dict['estimator']\n","  train_input_fn = train_and_eval_dict['train_input_fn']\n","  eval_input_fns = train_and_eval_dict['eval_input_fns']\n","  predict_input_fn = train_and_eval_dict['predict_input_fn']\n","  train_steps = train_and_eval_dict['train_steps']\n","\n","  export_strategies = [\n","      tf.contrib.learn.utils.saved_model_export_utils.make_export_strategy(\n","          serving_input_fn=predict_input_fn)\n","  ]\n","\n","  return tf.contrib.learn.Experiment(\n","      estimator=estimator,\n","      train_input_fn=train_input_fn,\n","      eval_input_fn=eval_input_fns[0],\n","      train_steps=train_steps,\n","      eval_steps=None,\n","      export_strategies=export_strategies,\n","      eval_delay_secs=120,\n","  )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"efWqV7LlzB11","colab_type":"code","outputId":"144aba5d-982a-428f-f0ae-382bb0f2f6ef","executionInfo":{"status":"ok","timestamp":1560714527075,"user_tz":-120,"elapsed":1446,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","from absl import flags\n","\n","import tensorflow as tf\n","\n","from object_detection import model_hparams\n","#from object_detection import model_lib\n","\n","\n","from tensorflow.python import debug as tf_debug\n","\n","try:\n","  flags.DEFINE_string(\n","      'model_dir', None, 'Path to output model directory '\n","      'where event and checkpoint files will be written.')\n","except:\n","  print(\"model_dir already defined\")\n","try:\n","  flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\n","                      'file.')\n","except:\n","  print(\"pipeline_config_path already defined\")\n","try:\n","  flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\n","except:\n","  print(\"num_train_steps already defined\")\n","try:\n","  flags.DEFINE_boolean('eval_training_data', False,\n","                       'If training data should be evaluated for this job. Note '\n","                       'that one call only use this in eval-only mode, and '\n","                       '`checkpoint_dir` must be supplied.')\n","except:\n","  print(\"eval_training_data already defined\")\n","try:\n","  flags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\n","                       'every n eval input examples, where n is provided.')\n","except:\n","  print(\"sample_1_of_n_eval_examples already defined\")\n","try:\n","  flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n","                       'one of every n train input examples for evaluation, '\n","                       'where n is provided. This is only used if '\n","                       '`eval_training_data` is True.')\n","except:\n","  print(\"sample_1_of_n_eval_on_train_examples already defined\")\n","try:\n","  flags.DEFINE_string(\n","      'hparams_overrides', None, 'Hyperparameter overrides, '\n","      'represented as a string containing comma-separated '\n","      'hparam_name=value pairs.')\n","except:\n","  print(\"hparams_overrides already defined\")\n","try:\n","  flags.DEFINE_string(\n","      'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n","      '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n","      'writing resulting metrics to `model_dir`.')\n","except:\n","  print(\"checkpoint_dir already defined\")\n","try:\n","  flags.DEFINE_boolean(\n","      'run_once', False, 'If running in eval-only mode, whether to run just '\n","      'one round of eval vs running continuously (default).')\n","except:\n","  print(\"run_once already defined\")\n","\n","def main(unused_argv):\n","  flags.mark_flag_as_required('model_dir')\n","  flags.mark_flag_as_required('pipeline_config_path')\n","  \n","  #maybe we want debugging?\n","  hooks = [tf_debug.LocalCLIDebugHook()]\n","  \n","  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,\n","                                  session_config=tf.ConfigProto(log_device_placement=True),\n","                                  save_checkpoints_steps = FLAGS_OD.save_checkpoints_steps,\n","                                  save_checkpoints_secs = FLAGS_OD.save_checkpoints_secs)\n","\n","#  train_and_eval_dict = model_lib.create_estimator_and_inputs(\n","  train_and_eval_dict = create_estimator_and_inputs(\n","      run_config=config,\n","      hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),\n","      pipeline_config_path=FLAGS.pipeline_config_path,\n","      train_steps=FLAGS.num_train_steps,\n","      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n","      sample_1_of_n_eval_on_train_examples=(\n","          FLAGS.sample_1_of_n_eval_on_train_examples))\n","  estimator = train_and_eval_dict['estimator']\n","  train_input_fn = train_and_eval_dict['train_input_fn']\n","  eval_input_fns = train_and_eval_dict['eval_input_fns']\n","  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\n","  predict_input_fn = train_and_eval_dict['predict_input_fn']\n","  train_steps = train_and_eval_dict['train_steps']\n","  \n","  if FLAGS.checkpoint_dir:\n","    if FLAGS.eval_training_data:\n","      name = 'training_data'\n","      input_fn = eval_on_train_input_fn\n","    else:\n","      name = 'validation_data'\n","      # The first eval input will be evaluated.\n","      input_fn = eval_input_fns[0]\n","    if FLAGS.run_once:\n","      estimator.evaluate(input_fn,\n","                         num_eval_steps=None,\n","                         checkpoint_path=tf.train.latest_checkpoint(\n","                             FLAGS.checkpoint_dir))\n","    else:\n","      #model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n","      continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n","                                train_steps, name)\n","  else:\n","    #train_spec, eval_specs = model_lib.create_train_and_eval_specs(\n","    train_spec, eval_specs = create_train_and_eval_specs(\n","        train_input_fn,\n","        eval_input_fns,\n","        eval_on_train_input_fn,\n","        predict_input_fn,\n","        train_steps,\n","        eval_on_train_data=False)\n","    \n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["model_dir already defined\n","pipeline_config_path already defined\n","num_train_steps already defined\n","eval_training_data already defined\n","sample_1_of_n_eval_examples already defined\n","sample_1_of_n_eval_on_train_examples already defined\n","hparams_overrides already defined\n","checkpoint_dir already defined\n","run_once already defined\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0kGhlxgvUORQ","colab_type":"code","colab":{}},"source":["!cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/ConfigFiles/faster_rcnn_inception_resnet_v2_atrous_holoselecta.config pipeline.config"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cE5mBvnkT3vb","colab_type":"code","outputId":"a367ffd5-abb4-4df7-c081-5289d00ac9a4","colab":{"base_uri":"https://localhost:8080/","height":4587},"executionInfo":{"status":"ok","timestamp":1560718800218,"user_tz":-120,"elapsed":4264741,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}}},"source":["from subprocess import call\n","\n","FLAGS = flags.FLAGS\n","FLAGS.pipeline_config_path = \"pipeline.config\"\n","FLAGS_OD.save_checkpoints_steps = 3500\n","FLAGS_OD.throttle_secs = 600\n","FLAGS_OD.save_checkpoints_secs = None\n","FLAGS.eval_training_data = False\n","\n","\n","res = 320\n","for it in [10]:\n","  ret1 = call('gsutil cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/TFRecords/2019_6_15_15_31_42_test_{}_{}.record gs://holoselecta_objectdetection/holoselecta/data/val.record'.format(res,it), shell=True)\n","  ret2 = call('gsutil cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/TFRecords/2019_6_15_15_31_42_train_{}_{}.record gs://holoselecta_objectdetection/holoselecta/data/train.record'.format(res,it), shell=True)\n","  ret3 = call('gsutil cp /content/gdrive/My\\ Drive/Masterarbeit/ObjectDetection/LabelMaps/2019_6_15_15_31_42.pbtxt gs://holoselecta_objectdetection/holoselecta/data/label_map.pbtxt', shell=True)\n","  \n","  FLAGS.model_dir = \"gs://holoselecta_objectdetection/inception_4/{}/{}/\".format(res,it)\n","  \n","  try:\n","    tf.app.run(main)\n","  except:\n","    print(\"################  {}  ###############\".format(it))\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["W0616 19:49:04.565367 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/utils/config_util.py:98: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0616 19:49:04.593217 139855874557824 <ipython-input-9-c0786977b453>:543] Forced number of epochs for all eval validations to be 1.\n","W0616 19:49:04.596871 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/utils/config_util.py:484: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","I0616 19:49:04.602991 139855874557824 config_util.py:484] Maybe overwriting train_steps: None\n","I0616 19:49:04.606081 139855874557824 config_util.py:484] Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0616 19:49:04.609277 139855874557824 config_util.py:484] Maybe overwriting eval_num_epochs: 1\n","I0616 19:49:04.610782 139855874557824 config_util.py:484] Maybe overwriting load_pretrained: True\n","I0616 19:49:04.614385 139855874557824 config_util.py:494] Ignoring config override key: load_pretrained\n","W0616 19:49:04.615487 139855874557824 <ipython-input-9-c0786977b453>:559] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","I0616 19:49:04.617788 139855874557824 <ipython-input-9-c0786977b453>:592] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0616 19:49:04.619048 139855874557824 estimator.py:209] Using config: {'_model_dir': 'gs://holoselecta_objectdetection/inception_4/320/10/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 3500, '_save_checkpoints_secs': None, '_session_config': log_device_placement: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f325ee074a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","W0616 19:49:04.620158 139855874557824 model_fn.py:621] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f325edf6b70>) includes params argument, but params are not passed to Estimator.\n","I0616 19:49:04.623906 139855874557824 estimator_training.py:186] Not using Distribute Coordinator.\n","I0616 19:49:04.624978 139855874557824 training.py:612] Running training and evaluation locally (non-distributed).\n","I0616 19:49:04.626190 139855874557824 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 3500 or save_checkpoints_secs None.\n","W0616 19:49:08.169927 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0616 19:49:08.189054 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/data_decoders/tf_example_decoder.py:177: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0616 19:49:08.189911 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/data_decoders/tf_example_decoder.py:192: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0616 19:49:08.815124 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0616 19:49:09.001766 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0616 19:49:09.002715 139855874557824 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n","W0616 19:49:09.012820 139855874557824 deprecation.py:323] From tf/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0616 19:49:09.013681 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0616 19:49:09.041894 139855874557824 deprecation.py:323] From tf/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0616 19:49:09.344528 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/utils/ops.py:485: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0616 19:49:09.351020 139855874557824 deprecation.py:323] From tf/research/object_detection/utils/ops.py:487: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0616 19:49:09.407440 139855874557824 deprecation.py:323] From tf/research/object_detection/core/preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0616 19:49:09.501296 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/core/preprocessor.py:2267: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0616 19:49:09.880064 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/inputs.py:399: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0616 19:49:09.928278 139855874557824 deprecation.py:323] From tf/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","I0616 19:49:09.943944 139855874557824 estimator.py:1145] Calling model_fn.\n","I0616 19:49:09.968276 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 19:49:09.969096 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 19:49:21.204610 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 19:49:21.270272 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 19:49:21.271409 139855874557824 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","W0616 19:49:22.585738 139855874557824 deprecation.py:506] From tf/research/object_detection/utils/spatial_transform_ops.py:410: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","I0616 19:49:22.609416 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 19:49:22.610343 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","W0616 19:49:24.139890 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","I0616 19:49:24.351210 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 19:49:24.628030 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","W0616 19:49:24.661599 139855874557824 deprecation.py:323] From tf/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2623: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0616 19:49:24.666420 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/utils/variables_helper.py:134: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0616 19:49:25.522658 139855874557824 variables_helper.py:152] Variable [global_step] is not available in checkpoint\n","W0616 19:49:29.738107 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/core/losses.py:172: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0616 19:49:29.740939 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/core/losses.py:178: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0616 19:49:29.801376 139855874557824 deprecation.py:323] From tf/research/object_detection/core/losses.py:343: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0616 19:49:30.077431 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0616 19:49:30.094795 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","I0616 19:49:41.282617 139855874557824 estimator.py:1147] Done calling model_fn.\n","I0616 19:49:41.285529 139855874557824 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","I0616 19:49:48.590542 139855874557824 monitored_session.py:240] Graph was finalized.\n","W0616 19:49:49.826468 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","I0616 19:49:50.014690 139855874557824 saver.py:1280] Restoring parameters from gs://holoselecta_objectdetection/inception_4/320/10/model.ckpt-3500\n","W0616 19:50:21.252741 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","I0616 19:50:23.746106 139855874557824 session_manager.py:500] Running local_init_op.\n","I0616 19:50:24.139178 139855874557824 session_manager.py:502] Done running local_init_op.\n","I0616 19:50:43.296458 139855874557824 basic_session_run_hooks.py:606] Saving checkpoints for 3500 into gs://holoselecta_objectdetection/inception_4/320/10/model.ckpt.\n","I0616 19:51:35.203118 139855874557824 basic_session_run_hooks.py:262] loss = 0.047247462, step = 3500\n","I0616 19:56:49.610346 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.318058\n","I0616 19:56:50.897139 139855874557824 basic_session_run_hooks.py:260] loss = 0.16384225, step = 3600 (315.694 sec)\n","I0616 19:59:16.196139 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.682194\n","I0616 19:59:17.381573 139855874557824 basic_session_run_hooks.py:260] loss = 0.15440358, step = 3700 (146.484 sec)\n","I0616 20:01:26.133018 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.769604\n","I0616 20:01:27.367059 139855874557824 basic_session_run_hooks.py:260] loss = 0.13340196, step = 3800 (129.986 sec)\n","I0616 20:03:16.838736 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.903296\n","I0616 20:03:16.845363 139855874557824 basic_session_run_hooks.py:260] loss = 0.03398069, step = 3900 (109.478 sec)\n","I0616 20:05:04.108990 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.932225\n","I0616 20:05:05.534047 139855874557824 basic_session_run_hooks.py:260] loss = 0.3252543, step = 4000 (108.689 sec)\n","I0616 20:06:51.214093 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.933662\n","I0616 20:06:51.216496 139855874557824 basic_session_run_hooks.py:260] loss = 0.03873705, step = 4100 (105.682 sec)\n","I0616 20:08:36.628896 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.948633\n","I0616 20:08:37.847206 139855874557824 basic_session_run_hooks.py:260] loss = 0.13976042, step = 4200 (106.631 sec)\n","I0616 20:10:20.994632 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.958169\n","I0616 20:10:20.997890 139855874557824 basic_session_run_hooks.py:260] loss = 0.13615336, step = 4300 (103.151 sec)\n","I0616 20:12:04.308012 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.967929\n","I0616 20:12:05.610293 139855874557824 basic_session_run_hooks.py:260] loss = 0.30543116, step = 4400 (104.612 sec)\n","I0616 20:13:49.979766 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.946327\n","I0616 20:13:49.982350 139855874557824 basic_session_run_hooks.py:260] loss = 0.18165335, step = 4500 (104.372 sec)\n","I0616 20:15:32.857304 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.97203\n","I0616 20:15:34.060922 139855874557824 basic_session_run_hooks.py:260] loss = 0.12942457, step = 4600 (104.079 sec)\n","I0616 20:17:17.454837 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.956045\n","I0616 20:17:17.457901 139855874557824 basic_session_run_hooks.py:260] loss = 0.050433952, step = 4700 (103.397 sec)\n","I0616 20:19:00.121600 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.974025\n","I0616 20:19:01.519968 139855874557824 basic_session_run_hooks.py:260] loss = 0.06451022, step = 4800 (104.062 sec)\n","I0616 20:20:44.585426 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.957269\n","I0616 20:20:44.589450 139855874557824 basic_session_run_hooks.py:260] loss = 0.022010492, step = 4900 (103.070 sec)\n","I0616 20:22:26.499186 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.981222\n","I0616 20:22:27.688211 139855874557824 basic_session_run_hooks.py:260] loss = 0.040453635, step = 5000 (103.099 sec)\n","I0616 20:24:08.341085 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.981914\n","I0616 20:24:08.347348 139855874557824 basic_session_run_hooks.py:260] loss = 0.01772562, step = 5100 (100.659 sec)\n","I0616 20:25:50.355984 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.980249\n","I0616 20:25:51.739575 139855874557824 basic_session_run_hooks.py:260] loss = 0.11113432, step = 5200 (103.392 sec)\n","I0616 20:27:33.389898 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.970555\n","I0616 20:27:33.394760 139855874557824 basic_session_run_hooks.py:260] loss = 0.029046794, step = 5300 (101.655 sec)\n","I0616 20:29:15.568068 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.978683\n","I0616 20:29:17.034696 139855874557824 basic_session_run_hooks.py:260] loss = 0.14049338, step = 5400 (103.640 sec)\n","I0616 20:30:58.816277 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.96854\n","I0616 20:30:58.818622 139855874557824 basic_session_run_hooks.py:260] loss = 0.07571036, step = 5500 (101.784 sec)\n","I0616 20:32:42.031684 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.968848\n","I0616 20:32:43.208826 139855874557824 basic_session_run_hooks.py:260] loss = 0.048876338, step = 5600 (104.390 sec)\n","I0616 20:34:25.890856 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.962842\n","I0616 20:34:25.896091 139855874557824 basic_session_run_hooks.py:260] loss = 0.053015485, step = 5700 (102.687 sec)\n","I0616 20:36:06.716916 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.991807\n","I0616 20:36:08.085416 139855874557824 basic_session_run_hooks.py:260] loss = 0.10739417, step = 5800 (102.189 sec)\n","I0616 20:37:49.567523 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.972284\n","I0616 20:37:49.572146 139855874557824 basic_session_run_hooks.py:260] loss = 0.06913364, step = 5900 (101.487 sec)\n","I0616 20:39:31.342020 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.982565\n","I0616 20:39:32.736792 139855874557824 basic_session_run_hooks.py:260] loss = 0.036348753, step = 6000 (103.165 sec)\n","I0616 20:41:15.340434 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.961553\n","I0616 20:41:15.345742 139855874557824 basic_session_run_hooks.py:260] loss = 0.06362712, step = 6100 (102.609 sec)\n","I0616 20:42:56.519063 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.988351\n","I0616 20:42:57.754102 139855874557824 basic_session_run_hooks.py:260] loss = 0.021982338, step = 6200 (102.408 sec)\n","I0616 20:44:40.009692 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.966272\n","I0616 20:44:40.015410 139855874557824 basic_session_run_hooks.py:260] loss = 0.18036273, step = 6300 (102.261 sec)\n","I0616 20:46:22.058614 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.979921\n","I0616 20:46:23.329248 139855874557824 basic_session_run_hooks.py:260] loss = 0.10326832, step = 6400 (103.314 sec)\n","I0616 20:48:06.248331 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.959787\n","I0616 20:48:06.253640 139855874557824 basic_session_run_hooks.py:260] loss = 0.07316543, step = 6500 (102.925 sec)\n","I0616 20:49:48.679219 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.976268\n","I0616 20:49:49.912753 139855874557824 basic_session_run_hooks.py:260] loss = 0.07037365, step = 6600 (103.659 sec)\n","I0616 20:51:32.402779 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.964102\n","I0616 20:51:32.407849 139855874557824 basic_session_run_hooks.py:260] loss = 0.11446719, step = 6700 (102.495 sec)\n","I0616 20:53:14.430660 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.980124\n","I0616 20:53:15.639537 139855874557824 basic_session_run_hooks.py:260] loss = 0.031202434, step = 6800 (103.232 sec)\n","I0616 20:54:56.905944 139855874557824 basic_session_run_hooks.py:692] global_step/sec: 0.975845\n","I0616 20:54:56.910928 139855874557824 basic_session_run_hooks.py:260] loss = 0.0237422, step = 6900 (101.271 sec)\n","I0616 20:56:38.354801 139855874557824 basic_session_run_hooks.py:606] Saving checkpoints for 7000 into gs://holoselecta_objectdetection/inception_4/320/10/model.ckpt.\n","I0616 20:57:05.865871 139855874557824 estimator.py:1145] Calling model_fn.\n","I0616 20:57:05.892694 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:05.893447 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:16.104362 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:16.169278 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:16.170340 139855874557824 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0616 20:57:16.888426 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:16.889412 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:18.447873 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:18.471975 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","W0616 20:57:22.457106 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n","Instructions for updating:\n","`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims` instead.\n","I0616 20:57:22.562964 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:57:22.563981 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","W0616 20:57:23.765355 139855874557824 deprecation.py:323] From tf/research/object_detection/eval_util.py:791: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0616 20:57:24.110576 139855874557824 deprecation.py:323] From tf/research/object_detection/utils/visualization_utils.py:492: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0616 20:57:24.285298 139855874557824 deprecation_wrapper.py:119] From tf/research/object_detection/utils/visualization_utils.py:1005: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","I0616 20:57:25.202677 139855874557824 estimator.py:1147] Done calling model_fn.\n","I0616 20:57:25.226866 139855874557824 evaluation.py:255] Starting evaluation at 2019-06-16T20:57:25Z\n","I0616 20:57:26.489005 139855874557824 monitored_session.py:240] Graph was finalized.\n","I0616 20:57:26.715382 139855874557824 saver.py:1280] Restoring parameters from gs://holoselecta_objectdetection/inception_4/320/10/model.ckpt-7000\n","I0616 20:57:57.728829 139855874557824 session_manager.py:500] Running local_init_op.\n","I0616 20:57:58.053511 139855874557824 session_manager.py:502] Done running local_init_op.\n","I0616 20:58:44.137635 139852394247936 coco_evaluation.py:200] Performing evaluation on 52 images.\n","I0616 20:58:44.142996 139852394247936 coco_tools.py:109] Loading and preparing annotation results...\n","I0616 20:58:44.150118 139852394247936 coco_tools.py:131] DONE (t=0.00s)\n"],"name":"stderr"},{"output_type":"stream","text":["creating index...\n","index created!\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.56s).\n","Accumulating evaluation results...\n","DONE (t=0.18s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.154\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.148\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"],"name":"stdout"},{"output_type":"stream","text":["I0616 20:58:45.206598 139855874557824 evaluation.py:275] Finished evaluation at 2019-06-16-20:58:45\n","I0616 20:58:45.207822 139855874557824 estimator.py:2039] Saving dict for global step 7000: DetectionBoxes_Precision/mAP = 0.13799901, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.24600121, DetectionBoxes_Precision/mAP (small) = 0.10709723, DetectionBoxes_Precision/mAP@.50IOU = 0.21567777, DetectionBoxes_Precision/mAP@.75IOU = 0.15390481, DetectionBoxes_Recall/AR@1 = 0.1466261, DetectionBoxes_Recall/AR@10 = 0.14816925, DetectionBoxes_Recall/AR@100 = 0.14816925, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.25685182, DetectionBoxes_Recall/AR@100 (small) = 0.11383286, Loss/BoxClassifierLoss/classification_loss = 2.8001966, Loss/BoxClassifierLoss/localization_loss = 0.63571835, Loss/RPNLoss/localization_loss = 0.2765192, Loss/RPNLoss/objectness_loss = 0.26482254, Loss/total_loss = 3.9772573, global_step = 7000, learning_rate = 0.00013081286, loss = 3.9772573\n","I0616 20:58:50.812202 139855874557824 estimator.py:2099] Saving 'checkpoint_path' summary for global step 7000: gs://holoselecta_objectdetection/inception_4/320/10/model.ckpt-7000\n","I0616 20:58:52.086824 139855874557824 exporter.py:410] Performing the final export in the end of training.\n","I0616 20:58:56.943415 139855874557824 estimator.py:1145] Calling model_fn.\n","I0616 20:58:56.947085 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:58:56.948585 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:08.683323 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:08.750587 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:08.751636 139855874557824 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0616 20:59:09.491954 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:09.492996 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:11.043941 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:11.068924 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:14.560632 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:14.561612 139855874557824 regularizers.py:98] Scale of 0 disables regularizer.\n","I0616 20:59:16.705176 139855874557824 estimator.py:1147] Done calling model_fn.\n","W0616 20:59:16.706282 139855874557824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","I0616 20:59:16.708113 139855874557824 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","I0616 20:59:16.709134 139855874557824 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","I0616 20:59:16.710057 139855874557824 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0616 20:59:16.711296 139855874557824 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","I0616 20:59:16.712106 139855874557824 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","I0616 20:59:16.946368 139855874557824 saver.py:1280] Restoring parameters from gs://holoselecta_objectdetection/inception_4/320/10/model.ckpt-7000\n","I0616 20:59:34.932857 139855874557824 builder_impl.py:661] Assets added to graph.\n","I0616 20:59:34.934350 139855874557824 builder_impl.py:456] No assets to write.\n","I0616 20:59:54.538860 139855874557824 builder_impl.py:421] SavedModel written to: gs://holoselecta_objectdetection/inception_4/320/10/export/Servo/temp-b'1560718732'/saved_model.pb\n","I0616 20:59:59.457871 139855874557824 estimator.py:368] Loss for final step: 0.038956665.\n"],"name":"stderr"},{"output_type":"stream","text":["################  10  ###############\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uBbjLbX1zq-h","colab_type":"code","outputId":"a9d7e7d0-3125-4636-b872-09ff5d24f634","executionInfo":{"status":"error","timestamp":1559109435534,"user_tz":-120,"elapsed":492604,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":3451}},"source":["from tensorboardcolab import TensorBoardColab\n","from datetime import datetime\n","from time import sleep\n","now = datetime.now()\n","timestamp = \"_\".join([str(now.year), str(now.month), str(now.day), str(now.hour), str(now.minute), str(now.second)])\n","\n","FLAGS = flags.FLAGS\n","FLAGS.pipeline_config_path = \"pipeline.config\"\n","FLAGS.num_train_steps = 7000\n","FLAGS_OD.save_checkpoints_steps = 1000\n","FLAGS_OD.throttle_secs = 120\n","FLAGS_OD.save_checkpoints_secs = None\n","FLAGS.eval_training_data = False\n","\n","\n","FLAGS.model_dir = \"gs://holoselecta_objectdetection/holoselecta/inception/640/archiv/\"\n","\n","#tf.logging.set_verbosity(tf.logging.DEBUG)\n","use_tensorboard = False\n","if use_tensorboard:\n","  tbc = TensorBoardColab(graph_path=FLAGS.model_dir)\n","  \n","tf.app.run(main)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n"],"name":"stdout"},{"output_type":"stream","text":["W0529 05:49:02.954575 139695153375104 <ipython-input-7-c0786977b453>:543] Forced number of epochs for all eval validations to be 1.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Maybe overwriting train_steps: 7000\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.956938 139695153375104 config_util.py:484] Maybe overwriting train_steps: 7000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.958777 139695153375104 config_util.py:484] Maybe overwriting sample_1_of_n_eval_examples: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.960522 139695153375104 config_util.py:484] Maybe overwriting eval_num_epochs: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Maybe overwriting load_pretrained: True\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.962687 139695153375104 config_util.py:484] Maybe overwriting load_pretrained: True\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Ignoring config override key: load_pretrained\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.964425 139695153375104 config_util.py:494] Ignoring config override key: load_pretrained\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n"],"name":"stdout"},{"output_type":"stream","text":["W0529 05:49:02.968572 139695153375104 <ipython-input-7-c0786977b453>:559] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.971482 139695153375104 <ipython-input-7-c0786977b453>:592] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'gs://holoselecta_objectdetection/holoselecta/inception/640/archiv/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': log_device_placement: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0cb3235630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.973153 139695153375104 estimator.py:201] Using config: {'_model_dir': 'gs://holoselecta_objectdetection/holoselecta/inception/640/archiv/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': log_device_placement: true\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0cb3235630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f0cb3239378>) includes params argument, but params are not passed to Estimator.\n"],"name":"stdout"},{"output_type":"stream","text":["W0529 05:49:02.976264 139695153375104 estimator.py:1924] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f0cb3239378>) includes params argument, but params are not passed to Estimator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Not using Distribute Coordinator.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.978060 139695153375104 estimator_training.py:185] Not using Distribute Coordinator.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.980533 139695153375104 training.py:610] Running training and evaluation locally (non-distributed).\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:02.982593 139695153375104 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n"],"name":"stdout"},{"output_type":"stream","text":["W0529 05:49:03.452638 139695153375104 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:04.307888 139695153375104 estimator.py:1111] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:04.335511 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:04.337430 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:15.773611 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:15.841112 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:depth of additional conv before box predictor: 0\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:15.842675 139695153375104 convolutional_box_predictor.py:150] depth of additional conv before box predictor: 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:16.772482 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:16.774399 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:18.265992 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:18.289997 139695153375104 regularizers.py:98] Scale of 0 disables regularizer.\n","W0529 05:49:18.506350 139695153375104 variables_helper.py:149] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[360]], model variable shape: [[156]]. This variable will not be initialized from the checkpoint.\n","W0529 05:49:18.507328 139695153375104 variables_helper.py:149] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1536, 360]], model variable shape: [[1536, 156]]. This variable will not be initialized from the checkpoint.\n","W0529 05:49:18.511816 139695153375104 variables_helper.py:149] Variable [SecondStageBoxPredictor/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[91]], model variable shape: [[40]]. This variable will not be initialized from the checkpoint.\n","W0529 05:49:18.513219 139695153375104 variables_helper.py:149] Variable [SecondStageBoxPredictor/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1536, 91]], model variable shape: [[1536, 40]]. This variable will not be initialized from the checkpoint.\n","W0529 05:49:18.519360 139695153375104 variables_helper.py:152] Variable [global_step] is not available in checkpoint\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:33.556545 139695153375104 estimator.py:1113] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:33.560092 139695153375104 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:49:41.286311 139695153375104 monitored_session.py:222] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:50:22.710392 139695153375104 session_manager.py:491] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:50:23.310749 139695153375104 session_manager.py:493] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into gs://holoselecta_objectdetection/holoselecta/inception/640/archiv/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:50:43.012109 139695153375104 basic_session_run_hooks.py:594] Saving checkpoints for 0 into gs://holoselecta_objectdetection/holoselecta/inception/640/archiv/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 5.5027623, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:51:13.157898 139695153375104 basic_session_run_hooks.py:249] loss = 5.5027623, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.777611\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:53:21.756497 139695153375104 basic_session_run_hooks.py:680] global_step/sec: 0.777611\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 2.7271173, step = 100 (129.445 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:53:22.602957 139695153375104 basic_session_run_hooks.py:247] loss = 2.7271173, step = 100 (129.445 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.835511\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:55:21.443764 139695153375104 basic_session_run_hooks.py:680] global_step/sec: 0.835511\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 199.75543, step = 200 (118.850 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:55:21.452889 139695153375104 basic_session_run_hooks.py:247] loss = 199.75543, step = 200 (118.850 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.929711\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:57:09.003993 139695153375104 basic_session_run_hooks.py:680] global_step/sec: 0.929711\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 2.7478952, step = 300 (108.603 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0529 05:57:10.056204 139695153375104 basic_session_run_hooks.py:247] loss = 2.7478952, step = 300 (108.603 sec)\n"],"name":"stderr"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Found Inf or NaN global norm. : Tensor had Inf values\n\t [[{{node VerifyFinite/CheckNumerics}}]]\n\t [[{{node control_dependency}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-f577c85e967e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mtbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoardColab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-4c34c302ab51>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m         eval_on_train_data=False)\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    610\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Found Inf or NaN global norm. : Tensor had Inf values\n\t [[node VerifyFinite/CheckNumerics (defined at <ipython-input-7-c0786977b453>:355) ]]\n\t [[node control_dependency (defined at <ipython-input-7-c0786977b453>:355) ]]\n\nCaused by op 'VerifyFinite/CheckNumerics', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-f577c85e967e>\", line 22, in <module>\n    tf.app.run(main)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-8-4c34c302ab51>\", line 125, in main\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n    return executor.run()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n    return self.run_local()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n    saving_listeners=saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1154, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1112, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-7-c0786977b453>\", line 355, in model_fn\n    name='')  # Preventing scope prefix on all variables.\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 260, in optimize_loss\n    gradients = _clip_gradients_by_norm(gradients, clip_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 306, in _clip_gradients_by_norm\n    clipped_gradients, _ = clip_ops.clip_by_global_norm(gradients, clip_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py\", line 271, in clip_by_global_norm\n    \"Found Inf or NaN global norm.\")\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/numerics.py\", line 44, in verify_tensor_all_finite\n    return verify_tensor_all_finite_v2(t, msg, name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/numerics.py\", line 62, in verify_tensor_all_finite_v2\n    verify_input = array_ops.check_numerics(x, message=message)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 919, in check_numerics\n    \"CheckNumerics\", tensor=tensor, message=message, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Found Inf or NaN global norm. : Tensor had Inf values\n\t [[node VerifyFinite/CheckNumerics (defined at <ipython-input-7-c0786977b453>:355) ]]\n\t [[node control_dependency (defined at <ipython-input-7-c0786977b453>:355) ]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"P4zwYJmzzHrc","colab_type":"text"},"source":["## normal"]},{"cell_type":"code","metadata":{"id":"6I8GgjHyvRAI","colab_type":"code","outputId":"6d8b5fd5-885d-42a9-9028-08ede2e8132c","executionInfo":{"status":"error","timestamp":1548315427221,"user_tz":-60,"elapsed":3196324,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":6825}},"source":["from object_detection.model_main import FLAGS, main\n","\n","from datetime import datetime\n","now = datetime.now()\n","timestamp = \"_\".join([str(now.year), str(now.month), str(now.day), str(now.hour), str(now.minute), str(now.second)])\n","\n","FLAGS.pipeline_config_path = \"pipeline.config\"\n","try:\n","  print(\"creating test_model dir\")\n","  os.mkdir(\"test_model\")\n","except:\n","  print(\"test model dir already exists\")\n","FLAGS.model_dir = \"test_model/{}\".format(timestamp)\n","FLAGS.num_train_steps = 20000\n","FLAGS.sample_1_of_n_eval_examples = 1\n","\n","#tf.logging.set_verbosity(tf.logging.DEBUG)\n","\n","tf.app.run(main)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["creating test_model dir\n","test model dir already exists\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 20000\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'test_model/2019_1_24_6_43_50', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0cdefa82e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f0cdee25620>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into test_model/2019_1_24_6_43_50/model.ckpt.\n","INFO:tensorflow:loss = 6.065023, step = 1\n","INFO:tensorflow:global_step/sec: 0.186078\n","INFO:tensorflow:loss = 1.2273982, step = 101 (537.411 sec)\n","INFO:tensorflow:Saving checkpoints for 111 into test_model/2019_1_24_6_43_50/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-01-24-06:54:27\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from test_model/2019_1_24_6_43_50/model.ckpt-111\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.01s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.29s).\n","Accumulating evaluation results...\n","DONE (t=0.18s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n","INFO:tensorflow:Finished evaluation at 2019-01-24-06:55:09\n","INFO:tensorflow:Saving dict for global step 111: DetectionBoxes_Precision/mAP = 0.0017879014, DetectionBoxes_Precision/mAP (large) = 0.0023977566, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.009894382, DetectionBoxes_Precision/mAP@.75IOU = 5.9598726e-05, DetectionBoxes_Recall/AR@1 = 0.00020576132, DetectionBoxes_Recall/AR@10 = 0.02345679, DetectionBoxes_Recall/AR@100 = 0.02962963, DetectionBoxes_Recall/AR@100 (large) = 0.036277104, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.06973679, Loss/BoxClassifierLoss/localization_loss = 0.039061863, Loss/RPNLoss/localization_loss = 0.2577604, Loss/RPNLoss/objectness_loss = 0.62738425, Loss/total_loss = 0.9939433, global_step = 111, learning_rate = 0.0002, loss = 0.9939433\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 111: test_model/2019_1_24_6_43_50/model.ckpt-111\n","INFO:tensorflow:global_step/sec: 0.169805\n","INFO:tensorflow:loss = 1.4425247, step = 201 (588.911 sec)\n","INFO:tensorflow:Saving checkpoints for 213 into test_model/2019_1_24_6_43_50/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-01-24-07:04:28\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from test_model/2019_1_24_6_43_50/model.ckpt-213\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.31s).\n","Accumulating evaluation results...\n","DONE (t=0.19s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.034\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.047\n","INFO:tensorflow:Finished evaluation at 2019-01-24-07:05:11\n","INFO:tensorflow:Saving dict for global step 213: DetectionBoxes_Precision/mAP = 0.0057989126, DetectionBoxes_Precision/mAP (large) = 0.008657251, DetectionBoxes_Precision/mAP (medium) = 0.0022492467, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.011529858, DetectionBoxes_Precision/mAP@.75IOU = 0.0042981864, DetectionBoxes_Recall/AR@1 = 0.012317298, DetectionBoxes_Recall/AR@10 = 0.034097135, DetectionBoxes_Recall/AR@100 = 0.035146516, DetectionBoxes_Recall/AR@100 (large) = 0.046988796, DetectionBoxes_Recall/AR@100 (medium) = 0.0023715415, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.05902868, Loss/BoxClassifierLoss/localization_loss = 0.029617606, Loss/RPNLoss/localization_loss = 0.25125268, Loss/RPNLoss/objectness_loss = 0.5258371, Loss/total_loss = 0.8657361, global_step = 213, learning_rate = 0.0002, loss = 0.8657361\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 213: test_model/2019_1_24_6_43_50/model.ckpt-213\n","INFO:tensorflow:global_step/sec: 0.168142\n","INFO:tensorflow:loss = 1.6919546, step = 301 (594.737 sec)\n","INFO:tensorflow:Saving checkpoints for 315 into test_model/2019_1_24_6_43_50/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-01-24-07:14:33\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from test_model/2019_1_24_6_43_50/model.ckpt-315\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.30s).\n","Accumulating evaluation results...\n","DONE (t=0.18s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.049\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.027\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.042\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.043\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.059\n","INFO:tensorflow:Finished evaluation at 2019-01-24-07:15:17\n","INFO:tensorflow:Saving dict for global step 315: DetectionBoxes_Precision/mAP = 0.023038365, DetectionBoxes_Precision/mAP (large) = 0.030923985, DetectionBoxes_Precision/mAP (medium) = 0.0027012483, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.0487916, DetectionBoxes_Precision/mAP@.75IOU = 0.010758814, DetectionBoxes_Recall/AR@1 = 0.026539663, DetectionBoxes_Recall/AR@10 = 0.04185256, DetectionBoxes_Recall/AR@100 = 0.042624168, DetectionBoxes_Recall/AR@100 (large) = 0.05948646, DetectionBoxes_Recall/AR@100 (medium) = 0.004150198, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.098953225, Loss/BoxClassifierLoss/localization_loss = 0.08256231, Loss/RPNLoss/localization_loss = 0.25106788, Loss/RPNLoss/objectness_loss = 0.42894232, Loss/total_loss = 0.8615258, global_step = 315, learning_rate = 0.0002, loss = 0.8615258\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 315: test_model/2019_1_24_6_43_50/model.ckpt-315\n","INFO:tensorflow:global_step/sec: 0.168285\n","INFO:tensorflow:loss = 0.5246303, step = 401 (594.229 sec)\n","INFO:tensorflow:Saving checkpoints for 416 into test_model/2019_1_24_6_43_50/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-01-24-07:24:33\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from test_model/2019_1_24_6_43_50/model.ckpt-416\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.34s).\n","Accumulating evaluation results...\n","DONE (t=0.20s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.084\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.035\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.094\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.116\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n","INFO:tensorflow:Finished evaluation at 2019-01-24-07:25:16\n","INFO:tensorflow:Saving dict for global step 416: DetectionBoxes_Precision/mAP = 0.042031966, DetectionBoxes_Precision/mAP (large) = 0.04805714, DetectionBoxes_Precision/mAP (medium) = 0.035449725, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.08358183, DetectionBoxes_Precision/mAP@.75IOU = 0.035064198, DetectionBoxes_Recall/AR@1 = 0.04766461, DetectionBoxes_Recall/AR@10 = 0.09382726, DetectionBoxes_Recall/AR@100 = 0.10387135, DetectionBoxes_Recall/AR@100 (large) = 0.10352371, DetectionBoxes_Recall/AR@100 (medium) = 0.11580549, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.207374, Loss/BoxClassifierLoss/localization_loss = 0.14279708, Loss/RPNLoss/localization_loss = 0.25061733, Loss/RPNLoss/objectness_loss = 0.36163518, Loss/total_loss = 0.96242356, global_step = 416, learning_rate = 0.0002, loss = 0.96242356\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 416: test_model/2019_1_24_6_43_50/model.ckpt-416\n","INFO:tensorflow:global_step/sec: 0.170137\n","INFO:tensorflow:loss = 1.3190968, step = 501 (587.762 sec)\n","INFO:tensorflow:Saving checkpoints for 519 into test_model/2019_1_24_6_43_50/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2019-01-24-07:34:37\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from test_model/2019_1_24_6_43_50/model.ckpt-519\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.31s).\n","Accumulating evaluation results...\n","DONE (t=0.19s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.098\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.072\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.060\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.120\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n","INFO:tensorflow:Finished evaluation at 2019-01-24-07:35:20\n","INFO:tensorflow:Saving dict for global step 519: DetectionBoxes_Precision/mAP = 0.050575554, DetectionBoxes_Precision/mAP (large) = 0.058461163, DetectionBoxes_Precision/mAP (medium) = 0.071797654, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.098250225, DetectionBoxes_Precision/mAP@.75IOU = 0.048989344, DetectionBoxes_Recall/AR@1 = 0.060361348, DetectionBoxes_Recall/AR@10 = 0.119529486, DetectionBoxes_Recall/AR@100 = 0.13663708, DetectionBoxes_Recall/AR@100 (large) = 0.11613186, DetectionBoxes_Recall/AR@100 (medium) = 0.19871542, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.23900433, Loss/BoxClassifierLoss/localization_loss = 0.18649054, Loss/RPNLoss/localization_loss = 0.24904318, Loss/RPNLoss/objectness_loss = 0.32134953, Loss/total_loss = 0.9958875, global_step = 519, learning_rate = 0.0002, loss = 0.9958875\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 519: test_model/2019_1_24_6_43_50/model.ckpt-519\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-816445fe95a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#tf.logging.set_verbosity(tf.logging.DEBUG)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/tf/research/object_detection/model_main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Currently only a single Eval Spec is allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    609\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"3hle2DbfXZey","colab_type":"text"},"source":["# Copy & Save"]},{"cell_type":"code","metadata":{"id":"0uZOx0fLXYho","colab_type":"code","outputId":"b015fa07-1927-4a82-e392-c2791ed0b635","executionInfo":{"status":"ok","timestamp":1557263107135,"user_tz":-120,"elapsed":16693,"user":{"displayName":"Tobias Grundmann","photoUrl":"","userId":"08188606845298769954"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import shutil\n","import os\n","\n","timestamp = \"2019_5_7_19_42_14\"\n","\n","with open(\"test_model/{}/README.md\".format(timestamp), \"+w\") as f:\n","  f.write(\"# Model Description  \\n\")\n","  f.write(\"Model: SSD, Resnet 50, Focal Point Network (FPN), Shared Box Predictor, (aka RetinaNet)  \\n\")\n","  f.write(\"Input Resolution: 640 x 640  \\n\")\n","  f.write(\"Classes: 38  \\n\")\n","  f.write(\"Training Images: _Automat  \\n\")\n","  f.write(\"Dataset Timestamp: 2019_5_7_12_50_41  \\n\")\n","  f.write(\"Training Steps: 7000  \\n\")\n","  f.write(\"Final mAP@.50IOU = 0.69 ; mAP@.75IOU = 0.60  \\n\")\n","  f.write(\"Max Score Steps: 7000\")\n","\n","shutil.copy(\"model/frozen_inference_graph.pb\", \"test_model/{}/frozen_inference_graph.pb\".format(timestamp))\n","shutil.copy(\"data/label_map.pbtxt\", \"test_model/{}/label_map.pbtxt\".format(timestamp))\n","shutil.copy(\"pipeline.config\", \"test_model/{}/pipeline.config\".format(timestamp))\n","shutil.copy(\"timestamp\", \"test_model/{}/timestamp\".format(timestamp))\n","\n","shutil.copytree(\"test_model/{}\".format(timestamp), os.path.join(FLAGS_OD.model_dir, \"Good\", timestamp))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/My Drive/Masterarbeit/ObjectDetection/Models/Good/2019_5_7_19_42_14'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"UZYJ11x6sW9Z","colab_type":"text"},"source":["# Stuff"]},{"cell_type":"markdown","metadata":{"id":"EP7iD-uTsaQa","colab_type":"text"},"source":["These resolutions are problematic because we keep an entire queue of images in memory, not just the batch that you are currently training on. See e.g. the queue_capacity and min_after_dequeue parameters in https://github.com/tensorflow/models/blob/master/object_detection/protos/input_reader.proto"]},{"cell_type":"code","metadata":{"id":"zeM7SEdHsZZf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}